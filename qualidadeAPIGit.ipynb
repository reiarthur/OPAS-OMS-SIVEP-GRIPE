{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importar bibliotecas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from numpy import int64\r\n",
    "import time\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "#!pip install elasticsearch\r\n",
    "from elasticsearch import Elasticsearch\r\n",
    "import elasticsearch.helpers\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baixar base de dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "user = 'XXXXXX'\r\n",
    "pwd = 'XXXXXX'\r\n",
    "index = 'XXXXX'\r\n",
    "\r\n",
    "# Define a URL com usuario e senha\r\n",
    "url = 'https://' + user + ':' + pwd + '@elasticsearch-saps.saude.gov.br'\r\n",
    "\r\n",
    "# Faz uma requisição POST com a URL definida\r\n",
    "es = Elasticsearch([url], send_get_body_as='POST')\r\n",
    "\r\n",
    "# Verifica toda a base de dados disponível\r\n",
    "body={\"query\": {\"match_all\": {}}}\r\n",
    "\r\n",
    "# Cria um documento contendo a base de dados definida pelo index\r\n",
    "results = elasticsearch.helpers.scan(es, query=body, index=index)\r\n",
    "\r\n",
    "# Cria um Data Frame chamado df, com toda a base de dados de SRAG do DF\r\n",
    "df = pd.DataFrame.from_dict([document['_source'] for document in results])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 - Tratar os Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1 - Transformar colunas em maiúsculo e alterar ordem das colunas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# coloca o nome das colunas em maiúsculo\r\n",
    "df.columns = df.columns.str.upper()\r\n",
    "\r\n",
    "# Cria uma lista com o nome das colunas na ordem solicitada\r\n",
    "ordem_colunas = ['NU_NOTIFIC', 'DT_NOTIFIC', 'SEM_NOT', 'DT_SIN_PRI', 'SEM_PRI', 'SG_UF_NOT', 'ID_REGIONA', 'CO_REGIONA', 'ID_MUNICIP', 'CO_MUN_NOT', 'ID_UNIDADE',\r\n",
    " 'CO_UNI_NOT', 'NU_CPF', 'NM_PACIENT', 'CS_SEXO', 'DT_NASC', 'NU_IDADE_N', 'TP_IDADE', 'COD_IDADE', 'CS_GESTANT', 'CS_RACA', 'CS_ETINIA', 'CS_ESCOL_N', 'NM_MAE_PAC',\r\n",
    " 'NU_CEP', 'ID_PAIS', 'CO_PAIS', 'SG_UF', 'ID_RG_RESI', 'CO_RG_RESI', 'ID_MN_RESI', 'CO_MUN_RES', 'NM_BAIRRO', 'NM_LOGRADO', 'NU_NUMERO', 'NM_COMPLEM', 'NU_DDD_TEL',\r\n",
    " 'NU_TELEFON', 'CS_ZONA', 'SURTO_SG', 'NOSOCOMIAL', 'AVE_SUINO', 'FEBRE', 'TOSSE', 'GARGANTA', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'VOMITO', 'OUTRO_SIN',\r\n",
    " 'OUTRO_DES', 'FATOR_RISC', 'PUERPERA', 'CARDIOPATI', 'HEMATOLOGI', 'SIND_DOWN', 'HEPATICA', 'ASMA', 'DIABETES', 'NEUROLOGIC', 'PNEUMOPATI', 'IMUNODEPRE', 'RENAL',\r\n",
    " 'OBESIDADE', 'OBES_IMC', 'OUT_MORBI', 'MORB_DESC', 'VACINA', 'DT_UT_DOSE', 'MAE_VAC', 'DT_VAC_MAE', 'M_AMAMENTA', 'DT_DOSEUNI', 'DT_1_DOSE', 'DT_2_DOSE', 'ANTIVIRAL',\r\n",
    " 'TP_ANTIVIR', 'OUT_ANTIV', 'DT_ANTIVIR', 'HOSPITAL', 'DT_INTERNA', 'SG_UF_INTE', 'ID_RG_INTE', 'CO_RG_INTE', 'ID_MN_INTE', 'CO_MU_INTE', 'NM_UN_INTE', 'CO_UN_INTE',\r\n",
    " 'UTI', 'DT_ENTUTI', 'DT_SAIDUTI', 'SUPORT_VEN', 'RAIOX_RES', 'RAIOX_OUT', 'DT_RAIOX', 'AMOSTRA', 'DT_COLETA', 'TP_AMOSTRA', 'OUT_AMOST', 'REQUI_GAL', 'PCR_RESUL',\r\n",
    " 'DT_PCR', 'POS_PCRFLU', 'TP_FLU_PCR', 'PCR_FLUASU', 'FLUASU_OUT', 'PCR_FLUBLI', 'FLUBLI_OUT', 'POS_PCROUT', 'PCR_VSR', 'PCR_PARA1', 'PCR_PARA2', 'PCR_PARA3', 'PCR_PARA4',\r\n",
    " 'PCR_ADENO', 'PCR_METAP', 'PCR_BOCA', 'PCR_RINO', 'PCR_OUTRO', 'DS_PCR_OUT', 'LAB_PCR', 'CO_LAB_PCR', 'CLASSI_FIN', 'CLASSI_OUT', 'CRITERIO', 'EVOLUCAO', 'DT_EVOLUCA',\r\n",
    " 'DT_ENCERRA', 'OBSERVA', 'NOME_PROF', 'REG_PROF', 'DT_DIGITA', 'HISTO_VGM', 'PAIS_VGM', 'CO_PS_VGM', 'LO_PS_VGM', 'DT_VGM', 'DT_RT_VGM', 'PCR_SARS2', 'PAC_COCBO',\r\n",
    " 'PAC_DSCBO', 'OUT_ANIM', 'DOR_ABD', 'FADIGA', 'PERD_OLFT', 'PERD_PALA', 'TOMO_RES', 'TOMO_OUT', 'DT_TOMO', 'TP_TES_AN', 'DT_RES_AN', 'RES_AN', 'LAB_AN', 'CO_LAB_AN',\r\n",
    " 'POS_AN_FLU', 'TP_FLU_AN', 'POS_AN_OUT', 'AN_SARS2', 'AN_VSR', 'AN_PARA1', 'AN_PARA2', 'AN_PARA3', 'AN_ADENO', 'AN_OUTRO', 'DS_AN_OUT', 'TP_AM_SOR', 'SOR_OUT', 'DT_CO_SOR',\r\n",
    " 'TP_SOR', 'OUT_SOR', 'DT_RES', 'RES_IGG', 'RES_IGM', 'RES_IGA', 'NU_DO', 'POV_CT', 'TP_POV_CT', 'TEM_CPF', 'ESTRANG', 'NU_CNS', 'VACINA_COV', 'DOSE_1_COV', 'DOSE_2_COV',\r\n",
    " 'LAB_PR_COV', 'LOTE_1_COV', 'LOTE_2_COV', 'FNT_IN_COV']\r\n",
    " \r\n",
    "# Deixa as colunas na Ordem  da lista ordem_colunas\r\n",
    "df = df[ordem_colunas]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 -  Alterar os tipos de dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# Cria uma lista com as colunas que devem ser do tipo datetime\r\n",
    "datas = [\r\n",
    "'DT_NASC',\r\n",
    "'DT_DIGITA',\r\n",
    "'DT_SIN_PRI',\r\n",
    "'DT_INTERNA',\r\n",
    "'DT_ENTUTI',\r\n",
    "'DT_SAIDUTI',\r\n",
    "'DT_PCR',\r\n",
    "'DT_EVOLUCA',\r\n",
    "'DT_ENCERRA',\r\n",
    "'DT_COLETA',\r\n",
    "'DT_NOTIFIC'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# Cria uma lista com as colunas que devem ser do tipo float\r\n",
    "float_columns = [\r\n",
    " 'CO_REGIONA',\r\n",
    " 'CS_ESCOL_N',\r\n",
    " 'NU_CEP',\r\n",
    " 'CO_RG_RESI',\r\n",
    " 'NU_DDD_TEL',\r\n",
    " 'CS_ZONA',\r\n",
    " 'SURTO_SG',\r\n",
    " 'NOSOCOMIAL',\r\n",
    " 'AVE_SUINO',\r\n",
    " 'FEBRE',\r\n",
    " 'TOSSE',\r\n",
    " 'GARGANTA',\r\n",
    " 'DISPNEIA',\r\n",
    " 'DESC_RESP',\r\n",
    " 'SATURACAO',\r\n",
    " 'DIARREIA',\r\n",
    " 'VOMITO',\r\n",
    " 'OUTRO_SIN',\r\n",
    " 'PUERPERA',\r\n",
    " 'CARDIOPATI',\r\n",
    " 'HEMATOLOGI',\r\n",
    " 'SIND_DOWN',\r\n",
    " 'HEPATICA',\r\n",
    " 'ASMA',\r\n",
    " 'DIABETES',\r\n",
    " 'NEUROLOGIC',\r\n",
    " 'PNEUMOPATI',\r\n",
    " 'IMUNODEPRE',\r\n",
    " 'RENAL',\r\n",
    " 'OBESIDADE',\r\n",
    " 'OBES_IMC',\r\n",
    " 'OUT_MORBI',\r\n",
    " 'VACINA',\r\n",
    " 'MAE_VAC',\r\n",
    " 'M_AMAMENTA',\r\n",
    " 'DT_DOSEUNI',\r\n",
    " 'DT_1_DOSE',\r\n",
    " 'DT_2_DOSE',\r\n",
    " 'ANTIVIRAL',\r\n",
    " 'TP_ANTIVIR',\r\n",
    " 'HOSPITAL',\r\n",
    " 'CO_RG_INTE',\r\n",
    " 'CO_MU_INTE',\r\n",
    " 'CO_UN_INTE',\r\n",
    " 'UTI',\r\n",
    " 'SUPORT_VEN',\r\n",
    " 'RAIOX_RES',\r\n",
    " 'AMOSTRA',\r\n",
    " 'TP_AMOSTRA',\r\n",
    " 'REQUI_GAL',\r\n",
    " 'PCR_RESUL',\r\n",
    " 'POS_PCRFLU',\r\n",
    " 'TP_FLU_PCR',\r\n",
    " 'PCR_FLUASU',\r\n",
    " 'FLUASU_OUT',\r\n",
    " 'PCR_FLUBLI',\r\n",
    " 'FLUBLI_OUT',\r\n",
    " 'POS_PCROUT',\r\n",
    " 'PCR_VSR',\r\n",
    " 'PCR_PARA1',\r\n",
    " 'PCR_PARA2',\r\n",
    " 'PCR_PARA3',\r\n",
    " 'PCR_PARA4',\r\n",
    " 'PCR_ADENO',\r\n",
    " 'PCR_METAP',\r\n",
    " 'PCR_BOCA',\r\n",
    " 'PCR_RINO',\r\n",
    " 'PCR_OUTRO',\r\n",
    " 'CO_LAB_PCR',\r\n",
    " 'CLASSI_FIN',\r\n",
    " 'CRITERIO',\r\n",
    " 'EVOLUCAO',\r\n",
    " 'PAIS_VGM',\r\n",
    " 'CO_PS_VGM',\r\n",
    " 'LO_PS_VGM',\r\n",
    " 'DT_VGM',\r\n",
    " 'DT_RT_VGM',\r\n",
    " 'PCR_SARS2',\r\n",
    " 'DOR_ABD',\r\n",
    " 'FADIGA',\r\n",
    " 'PERD_OLFT',\r\n",
    " 'PERD_PALA',\r\n",
    " 'RES_AN',\r\n",
    " 'CO_LAB_AN',\r\n",
    " 'POS_AN_FLU',\r\n",
    " 'TP_FLU_AN',\r\n",
    " 'POS_AN_OUT',\r\n",
    " 'AN_SARS2',\r\n",
    " 'AN_VSR',\r\n",
    " 'AN_PARA1',\r\n",
    " 'AN_PARA2',\r\n",
    " 'AN_PARA3',\r\n",
    " 'AN_ADENO',\r\n",
    " 'AN_OUTRO',\r\n",
    " 'RES_IGG',\r\n",
    " 'RES_IGM',\r\n",
    " 'RES_IGA',\r\n",
    " 'POV_CT',\r\n",
    " 'TEM_CPF',\r\n",
    " 'ESTRANG',\r\n",
    " 'NU_CNS',\r\n",
    " 'VACINA_COV',\r\n",
    " 'FNT_IN_COV',\r\n",
    " 'SEM_NOT',\r\n",
    " 'SEM_PRI',\r\n",
    " 'CO_MUN_NOT',\r\n",
    " 'CO_UNI_NOT',\r\n",
    " 'NU_IDADE_N',\r\n",
    " 'TP_IDADE',\r\n",
    " 'COD_IDADE',\r\n",
    " 'CS_GESTANT',\r\n",
    " 'CS_RACA',\r\n",
    " 'CO_PAIS',\r\n",
    " 'CO_MUN_RES',\r\n",
    " 'FATOR_RISC',\r\n",
    " 'HISTO_VGM',\r\n",
    " 'TOMO_RES',\r\n",
    " 'TP_TES_AN',\r\n",
    " 'TP_AM_SOR',\r\n",
    " 'TP_SOR',\r\n",
    " 'NU_DO'\r\n",
    " ]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# Cria uma lista com as colunas que devem ser do tipo object\r\n",
    "object_columns = [\r\n",
    " 'NU_NOTIFIC',\r\n",
    " 'SG_UF_NOT',\r\n",
    " 'ID_REGIONA',\r\n",
    " 'ID_MUNICIP',\r\n",
    " 'ID_UNIDADE',\r\n",
    " 'NU_CPF',\r\n",
    " 'NM_PACIENT',\r\n",
    " 'CS_SEXO',\r\n",
    " 'CS_ETINIA',\r\n",
    " 'NM_MAE_PAC',\r\n",
    " 'ID_PAIS',\r\n",
    " 'SG_UF',\r\n",
    " 'ID_RG_RESI',\r\n",
    " 'ID_MN_RESI',\r\n",
    " 'NM_BAIRRO',\r\n",
    " 'NM_LOGRADO',\r\n",
    " 'NU_NUMERO',\r\n",
    " 'NM_COMPLEM',\r\n",
    " 'NU_TELEFON',\r\n",
    " 'OUTRO_DES',\r\n",
    " 'MORB_DESC',\r\n",
    " 'DT_UT_DOSE',\r\n",
    " 'DT_VAC_MAE',\r\n",
    " 'OUT_ANTIV',\r\n",
    " 'DT_ANTIVIR',\r\n",
    " 'SG_UF_INTE',\r\n",
    " 'ID_RG_INTE',\r\n",
    " 'ID_MN_INTE',\r\n",
    " 'NM_UN_INTE',\r\n",
    " 'RAIOX_OUT',\r\n",
    " 'DT_RAIOX',\r\n",
    " 'OUT_AMOST',\r\n",
    " 'DS_PCR_OUT',\r\n",
    " 'LAB_PCR',\r\n",
    " 'CLASSI_OUT',\r\n",
    " 'OBSERVA',\r\n",
    " 'NOME_PROF',\r\n",
    " 'REG_PROF',\r\n",
    " 'PAC_COCBO',\r\n",
    " 'PAC_DSCBO',\r\n",
    " 'OUT_ANIM',\r\n",
    " 'TOMO_OUT',\r\n",
    " 'DT_TOMO',\r\n",
    " 'DT_RES_AN',\r\n",
    " 'LAB_AN',\r\n",
    " 'DS_AN_OUT',\r\n",
    " 'SOR_OUT',\r\n",
    " 'DT_CO_SOR',\r\n",
    " 'OUT_SOR',\r\n",
    " 'DT_RES',\r\n",
    " 'TP_POV_CT',\r\n",
    " 'DOSE_1_COV',\r\n",
    " 'DOSE_2_COV',\r\n",
    " 'LAB_PR_COV',\r\n",
    " 'LOTE_1_COV',\r\n",
    " 'LOTE_2_COV']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# Transforma as colunas de data para o tipo datetime64[ns]\r\n",
    "df[datas] = df[datas].apply(pd.to_datetime,infer_datetime_format = True, errors='coerce')\r\n",
    "\r\n",
    "# Transforma as colunas de float_columns para o tipo float\r\n",
    "df[float_columns] = df[float_columns].apply(pd.to_numeric, errors='coerce')\r\n",
    "\r\n",
    "# Transforma as colunas de object_columns para o tipo object\r\n",
    "df[object_columns] = df[object_columns].astype(object)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 - Criação e manipulação de variáveis essenciais"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# Cria a coluna IDADE_REGISTRO subtraindo a data do dia de registro no sistema pela data de nascimento, converte para ano e arredonda para nenhuma casa decimal\r\n",
    "df['IDADE_REGISTRO'] = ((df['DT_DIGITA'] - df['DT_NASC'])/ np.timedelta64(1, 'Y')).round()\r\n",
    "\r\n",
    "# Transforma a coluna 'NU_NOTIFIC' em string\r\n",
    "df['NU_NOTIFIC'] = df['NU_NOTIFIC'].apply(str)\r\n",
    "\r\n",
    "# Transforma a coluna de CPF em String e retira o .0 da direita\r\n",
    "df['NU_CPF'] = df['NU_CPF'].apply(str).apply(lambda x: x.replace('.0',''))\r\n",
    "\r\n",
    "# Cria uma coluna para reinternação e acrescenta 0 em todas as linhas, posteriormente, o que for identificado como reinternação terá 1\r\n",
    "df['REINTERNACAO'] = 0\r\n",
    "\r\n",
    "# Altera os valores que estãoe escritos como None para núlos\r\n",
    "df.replace('None', np.nan, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.4 - Criação de Filtro para casos do ano vigente"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# Cria uma lista com anos e seus inícios de calendários epidemológicos\r\n",
    "data = [[2020, '12/29/2019'], [2021, '01/03/2021'], [2022, '01/02/2022']]\r\n",
    " \r\n",
    "# Cria uma planilha com os anos e dias de início\r\n",
    "calendario_epidemologico = pd.DataFrame(data, columns = ['ANO', 'INICIO'])\r\n",
    "\r\n",
    "# Converte a coluna de dias para o tipo data\r\n",
    "calendario_epidemologico['INICIO'] = calendario_epidemologico['INICIO'].apply(pd.to_datetime,infer_datetime_format = True, errors='coerce')\r\n",
    "\r\n",
    "# Transforma a coluna de Ano em Index\r\n",
    "calendario_epidemologico.set_index('ANO', inplace = True)\r\n",
    "\r\n",
    "# Cria uma variável ano com o ano atual\r\n",
    "ano = datetime.now().year\r\n",
    "\r\n",
    "# Cria uma variável dia_calendario que recebe o primeiro dia da semana epidemologica do ano atual \r\n",
    "dia_calendario = calendario_epidemologico['INICIO'][ano]\r\n",
    "\r\n",
    "# Deixa na planilha df somente os registros a partir do primeiro dia de semana epidemologica do ano atual\r\n",
    "df = df.loc[df['DT_SIN_PRI']>= dia_calendario]\r\n",
    "\r\n",
    "# Reseta o index\r\n",
    "df.reset_index(drop = True, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 - Identificação de Registros Duplicados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# Cria um df com valores que se repetem em 'NM_PACIENT' e 'DT_NASC'\r\n",
    "df_nome = df[df[['NM_PACIENT','DT_NASC']].duplicated(keep=False)]\r\n",
    "\r\n",
    "# Cria o df df_cpf com os registros onde o cpf não são 'nan\r\n",
    "df_cpf = df[df['NU_CPF'].notnull()]\r\n",
    "# Deixa somente os registros duplicados\r\n",
    "df_cpf = df_cpf[df_cpf[['NU_CPF']].duplicated(keep=False)]\r\n",
    "\r\n",
    "# Junta os valores repetidos dos dois df acima\r\n",
    "df_repetidos = pd.concat([df_nome,df_cpf])\r\n",
    "\r\n",
    "# Apaga os registros que possuem valor repetido na coluna 'NU_NOTIFIC', deixando somente uma instância no 'df_repetidos'\r\n",
    "df_repetidos = df_repetidos.drop_duplicates(subset=['NU_NOTIFIC'], keep='last')\r\n",
    "\r\n",
    "# Apaga o 'df_nome', 'df_sem_nan_cpf' e o 'df_cpf'\r\n",
    "del df_cpf, df_nome        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.1 - Acrescentar descrição em REINTERNACAO\r\n",
    "### 0 = não possui repetição de nome nem CPF\r\n",
    "### 1 = Duplicidade que será mantida (Primeiro registro)\r\n",
    "### 2 = Duplicidade que será apagada (Segundo registro)\r\n",
    "### 3 = Reinternação ( Data de Primeiros Sintomas maior que 15 dias )\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# Cria um loop que vai percorrer a coluna 'NM_PACIENT' de df_repetidos\r\n",
    "for nome in df_repetidos['NM_PACIENT']:\r\n",
    "\r\n",
    "    # Cria a variável linhas e adiciona os valor do número de linahs com nomes iguais\r\n",
    "    linhas = df_repetidos.loc[df_repetidos['NM_PACIENT'] == nome].shape[0]\r\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \r\n",
    "    ids = [''] * linhas\r\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\r\n",
    "    for qtd in range(linhas):\r\n",
    "        # Adiciona o index das linhas em ordem na lista ids\r\n",
    "        ids[qtd] = df_repetidos.loc[df_repetidos['NM_PACIENT'] == nome]['REINTERNACAO'].index[qtd]\r\n",
    "        \r\n",
    "            \r\n",
    "    # Cria uma variável data com o registro das datas de 'DT_SIN_PRI' dos nomes repetidos \r\n",
    "    data = df_repetidos.loc[df_repetidos['NM_PACIENT'] == nome]['DT_SIN_PRI']\r\n",
    "\r\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \r\n",
    "    dif = [''] * linhas\r\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\r\n",
    "    for qtd in range(linhas):\r\n",
    "        # Adiciona na lista a diferença de dias entre o primeiro registro e os demais\r\n",
    "        dif[qtd] = (data[ids[qtd]] - data[ids[0]]).days \r\n",
    "    # Apaga o primeiro registro da lista dif (é zero por padrão)\r\n",
    "    del dif[0]\r\n",
    "\r\n",
    "    # Variável para pegar o índice de ids\r\n",
    "    i = 1\r\n",
    "    # Irá criar um loop que percorrerá os valores das diferenças em dif\r\n",
    "    for diferenca in dif:\r\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre 0 e 15 \r\n",
    "        if diferenca <= 15 and diferenca >= 0:\r\n",
    "\r\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 2\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\r\n",
    "            \r\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 1\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\r\n",
    "\r\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre -15 e 0\r\n",
    "        elif diferenca >= -15 and diferenca < 0:\r\n",
    "\r\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 1\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\r\n",
    "\r\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 2\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\r\n",
    "\r\n",
    "        # Caso a diferença entre o primeiro e o segundo dia seja maior que 15 dias ou menor que -15, executa os códigos abaixo dentro do else\r\n",
    "        else:\r\n",
    "\r\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 3\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\r\n",
    "            \r\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 3\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\r\n",
    "        i += 1\r\n",
    "\r\n",
    "              \r\n",
    "# Apaga os registros em df_repetidos onde o cpf for nulo\r\n",
    "df_repetidos = df_repetidos.loc[df_repetidos['NU_CPF'].notnull()]\r\n",
    "\r\n",
    "# Cria um loop que vai percorrer a coluna 'NM_PACIENT' de df_repetidos\r\n",
    "for cpf in df_repetidos['NU_CPF']:\r\n",
    "\r\n",
    "    # Cria a variável linhas e adiciona os valor do número de linahs com cpfs iguais\r\n",
    "    linhas = df_repetidos.loc[df_repetidos['NU_CPF'] == cpf].shape[0]\r\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \r\n",
    "    ids = [''] * linhas\r\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\r\n",
    "    for qtd in range(linhas):\r\n",
    "        # Adiciona o index das linhas em ordem na lista ids\r\n",
    "        ids[qtd] = df_repetidos.loc[df_repetidos['NU_CPF'] == cpf]['REINTERNACAO'].index[qtd]\r\n",
    "        \r\n",
    "            \r\n",
    "    # Cria uma variável data com o registro das datas de 'DT_SIN_PRI' dos cpfs repetidos \r\n",
    "    data = df_repetidos.loc[df_repetidos['NU_CPF'] == cpf]['DT_SIN_PRI']\r\n",
    "\r\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \r\n",
    "    dif = [''] * linhas\r\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\r\n",
    "    for qtd in range(linhas):\r\n",
    "        # Adiciona na lista a diferença de dias entre o primeiro registro e os demais\r\n",
    "        dif[qtd] = (data[ids[qtd]] - data[ids[0]]).days \r\n",
    "    # Apaga o primeiro registro da lista dif (é zero por padrão)\r\n",
    "    del dif[0]\r\n",
    "\r\n",
    "    # Variável para pegar o índice de ids\r\n",
    "    i = 1\r\n",
    "    # Irá criar um loop que percorrerá os valores das diferenças em dif\r\n",
    "    for diferenca in dif:\r\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre 0 e 15 \r\n",
    "        if diferenca <= 15 and diferenca >= 0:\r\n",
    "\r\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 2\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\r\n",
    "            \r\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 1\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\r\n",
    "\r\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre -15 e 0\r\n",
    "        elif diferenca >= -15 and diferenca < 0:\r\n",
    "\r\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 1\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\r\n",
    "\r\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 2\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\r\n",
    "\r\n",
    "        # Caso a diferença entre o primeiro e o segundo dia seja maior que 15 dias ou menor que -15, executa os códigos abaixo dentro do else\r\n",
    "        else:\r\n",
    "\r\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 3\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\r\n",
    "            \r\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\r\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\r\n",
    "                # Caso seja 0, ele vai receber 3\r\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\r\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\r\n",
    "        i += 1\r\n",
    "    \r\n",
    "# Apagas as variáveis usadas no código\r\n",
    "del df_repetidos, dif, diferenca, i, ids, linhas, nome,  qtd, data, cpf\r\n",
    "\r\n",
    "# transforma a coluna NU_NOTIFIC em index\r\n",
    "df.set_index('NU_NOTIFIC', inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.2 - Salva as planilhas com Descrição em Reinternação\r\n",
    "Para sonseguir salvar as planilhas, é necessária a criação de uma pasta chamada bases na mesma pasta que o código, e dentro da pasta bases criar uma pasta duplicidades, dentro de duplicidades criar duplicidades por hospitais."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# Cria uma cópia do df antes de converter as datas para gerar as planilhas\r\n",
    "dff = df.copy(deep=True)\r\n",
    "\r\n",
    "# Converte as colunas do tipo data que estão no formato americano para o brasileiro\r\n",
    "for data in datas:\r\n",
    "    df[data] = df[data].dt.strftime('%d/%m/%Y')\r\n",
    "\r\n",
    "del data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# Cria um df com os repetidos apagados \r\n",
    "df_repetidos_apagados = df.loc[df['REINTERNACAO']==2].sort_values(['NM_PACIENT'])\r\n",
    "# Salava uma planilha com os repetidos apagados\r\n",
    "df_repetidos_apagados.to_excel(\"bases/duplicidades/duplicidades_apagadas.xlsx\")\r\n",
    "\r\n",
    "\r\n",
    "# Cria uma planilha de apagados por hospitais\r\n",
    "df_repetidos_apagados_hospitais = df_repetidos_apagados\r\n",
    "\r\n",
    "# Salva uma planilha com os registros repetidos que não serão apagados\r\n",
    "df.loc[df['REINTERNACAO']==1].sort_values(['NM_PACIENT']).to_excel(\"bases/duplicidades/duplicidades_mantidas.xlsx\")\r\n",
    "\r\n",
    "# Todos valores repetidos desconsiderando as reinternações\r\n",
    "pd.concat([df.loc[df['REINTERNACAO']==2],df.loc[df['REINTERNACAO']==1]]).drop_duplicates(keep='last').sort_values(['NM_PACIENT']).to_excel(\"bases/duplicidades/duplicidades_sem_reinternacoes.xlsx\")\r\n",
    "\r\n",
    "# Salva uma planilha com todos os valores repetidos, incluindo as reinternações\r\n",
    "df.loc[df['REINTERNACAO']!=0].sort_values(['NM_PACIENT']).to_excel(\"bases/duplicidades/duplicidades_com_reinternacoes.xlsx\")\r\n",
    "\r\n",
    "# Salva uma planilha com todos os pacientes de reintenação\r\n",
    "df.loc[df['REINTERNACAO']==3].sort_values(['NM_PACIENT']).to_excel(\"bases/duplicidades/reinternacao.xlsx\")\r\n",
    "\r\n",
    "# Deixa no df somente os registros sem duplicidades, salvo os casos de reinternação\r\n",
    "df = df.loc[df['REINTERNACAO']!=2]\r\n",
    "\r\n",
    "# Salva uma planilha com \r\n",
    "df.to_excel(\"bases/planilha_tratada.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.3 - Salvar as planilhas de duplicidades de cada hospital"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# Define quais colunas irão ser enviadas para os Hospitais - A coluna de NU_NOTIFIC é o index da planilha e por isto não necessita estar definida aqui\r\n",
    "colunas_apagados = ['NU_CPF', 'NM_PACIENT', 'DT_NASC', 'ID_UNIDADE', 'DT_SIN_PRI']\r\n",
    "\r\n",
    "# Deixa na planilha df_repetidos_apagados_hospitais somente as colunas definidas a cima\r\n",
    "df_repetidos_apagados_hospitais = df_repetidos_apagados_hospitais[colunas_apagados]\r\n",
    "\r\n",
    "del colunas_apagados, df_repetidos_apagados, \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# Cria uma lista chamada hospitais com todos os nomes dos hospitais que aparecem na planilha df_repetidos_apagados_hospitais\r\n",
    "hospitais = df_repetidos_apagados_hospitais.ID_UNIDADE.unique()\r\n",
    "\r\n",
    "# Cria uma variável rota com a rota onde a planilha será salva, caso deseje musar isto, alterar aqui\r\n",
    "rota = 'bases/duplicidades/duplicidades por hospitais/'\r\n",
    "\r\n",
    "# Cria uma variável extencao que serve para definir a extensão da planilha a ser salva\r\n",
    "extencao = '.xlsx'\r\n",
    "\r\n",
    "# Cria um loop que irá ocorrer a quantidade de hospitais na planilha df_repetidos_apagados_hospitais\r\n",
    "for x in range(hospitais.shape[0]):\r\n",
    "    # Cria uma variável nome_hospital com o nome do hospital que está sendo percorrido pela lista\r\n",
    "    nome_hospital = hospitais[x]\r\n",
    "\r\n",
    "    # Cria uma variável salvar que junta a rota, nome do hospital e a extensão Ex: bases/planilha dos hospitais apagar/HRAN.xlsx\r\n",
    "    salvar = rota+nome_hospital+extencao\r\n",
    "\r\n",
    "    # Na posição da lista que o loop está percorrendo, é feito um df somente com os registros de repetidos a serem apagados do hospital e\r\n",
    "    # salva uma planilha com o nome do hospital na rota criada em rota\r\n",
    "    df_repetidos_apagados_hospitais.loc[df_repetidos_apagados_hospitais['ID_UNIDADE']==hospitais[x]].to_excel(salvar)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# Após gerar as planilhas, reatribui a df a planilha original com as datas no formato datetime\r\n",
    "df = dff\r\n",
    "\r\n",
    "# Deixa no df somente os registros sem duplicidades, salvo os casos de reinternação\r\n",
    "df = df.loc[df['REINTERNACAO']!=2]\r\n",
    "\r\n",
    "# Apaga variáveis não mais utilizadas\r\n",
    "del df_repetidos_apagados_hospitais, dff, extencao, hospitais, nome_hospital, "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 - Detectar Registros Inconsistentes ou Incompletos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# Cria uma lista com nome de novas colunas para definir os erros\r\n",
    "colunas_erros = ['HOMEM_PUERPERO', 'HOMEM_GRAVIDO', 'PREENCHER_UTI', 'PREENCHER_DATA_ENTRADA_UTI', 'PREENCHER_DATA_SAIDA_UTI', \r\n",
    "'OBITOS_SEM_HOSPITALIZACAO','CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5', 'PREENCHER_HOSPITALIZACAO', 'CURA_SEM_HOSPITALIZACAO', \r\n",
    "'PREENCHER_SUPORT_VEN', 'PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3', 'CLASSI_FIN_5_EVOLUCAO_2_E_CRITERIO_3', 'ENCERRADOS_IMCOMPLETOS', \r\n",
    "'PREENCHER_DT_ENCERRA', 'PREENCHER_CLASSI_FIN', 'PREENCHER_EVOLUCAO', 'CLASSI_FIN_4_CRITERIO_2_OU_4', 'SEM_SINTOMA', 'SRAG_LABORATORIAL_ERRADO', 'CLASSI_FIN_1_COVID_1']\r\n",
    "\r\n",
    "# Cria as colunas de erros em df e seta o valor 0 para todas as linhas das novas colunas\r\n",
    "df[colunas_erros] = 0\r\n",
    "\r\n",
    "# Redefine o index de df\r\n",
    "df = df.reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.1 - Identifica Homens classificados como Puerpera\r\n",
    "Nos registros onde o paciente é do sexo masculino e classificação \"Sim\" para puerpera, será escrito \"Sim\" na coluna 'HOMEM_PUERPERO'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# Homens classificados como Puérpera\r\n",
    "'HOMEM_PUERPERO'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde existe homem classificado como puérpera \r\n",
    "index_list = df.loc[df['CS_SEXO'] =='M'].loc[df['PUERPERA']==1,'HOMEM_PUERPERO'].index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna HOMEM_PUERPERO onde existe homeme classificado como puérpero\r\n",
    "df.loc[df.index[index_list],'HOMEM_PUERPERO'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.2 - Identifica Homens classificados como Gravida\r\n",
    "Nos registros onde o paciente é do sexo masculino e classificação \"Sim\" para Gravida, será escrito \"Sim\" na coluna 'HOMEM_GRAVIDO'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# Homens que não são classificados como CS_GESTANT (6), ignorado (9) ou 5 = Não\r\n",
    "'HOMEM_GRAVIDO'\r\n",
    "\r\n",
    "# Cria uma planilha somente com os registros de homens\r\n",
    "df_homem_gravido = df.loc[df['CS_SEXO']=='M']\r\n",
    "\r\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 1\r\n",
    "df_homem_gravido1 = df_homem_gravido.loc[df['CS_GESTANT']==1]\r\n",
    "\r\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 2\r\n",
    "df_homem_gravido2 = df_homem_gravido.loc[df['CS_GESTANT']==2]\r\n",
    "\r\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 3\r\n",
    "df_homem_gravido3 = df_homem_gravido.loc[df['CS_GESTANT']==3]\r\n",
    "\r\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 4\r\n",
    "df_homem_gravido4 = df_homem_gravido.loc[df['CS_GESTANT']==4]\r\n",
    "\r\n",
    "# Junta as colunas criadas a cima com cada código\r\n",
    "df_homem_gravido = pd.concat([df_homem_gravido1, df_homem_gravido2, df_homem_gravido3, df_homem_gravido4])\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros de homens classificados como grávidos\r\n",
    "index_list = df_homem_gravido.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna HOMEM_GRAVIDO onde existe homeme classificado como grávidos\r\n",
    "df.loc[df.index[index_list],'HOMEM_GRAVIDO'] = 'Sim'\r\n",
    "\r\n",
    "del df_homem_gravido\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.3 - Identifica casos onde a UTI está Ignorada ou nula\r\n",
    "Nos registros onde estiver 9 (ignorado) ou nulo na coluna UTI, será escrito \"Sim\" na coluna 'PREENCHER_UTI'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# UTI = 9 ou nula\r\n",
    "'PREENCHER_UTI'\r\n",
    "\r\n",
    "# Cria a planilha df_inconsistentes_UTI onde UTI está nula ou 9\r\n",
    "df_inconsistentes_UTI = pd.concat([df[df['UTI'].isna()],df.loc[df['UTI']==9]])\r\n",
    "\r\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_inconsistentes_UTI\r\n",
    "df_inconsistentes_UTI['SUBTRACAO_MES_ATUAL'] = 0\r\n",
    "\r\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_inconsistentes_UTI e subtrair pelo mês atual, oresultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\r\n",
    "for x in df_inconsistentes_UTI.index:\r\n",
    "    df_inconsistentes_UTI['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_inconsistentes_UTI['DT_SIN_PRI'][x]).days/30\r\n",
    "\r\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\r\n",
    "df_inconsistentes_UTI = df_inconsistentes_UTI.loc[df_inconsistentes_UTI['SUBTRACAO_MES_ATUAL'] >= 6]\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e UTI está nula ou 9\r\n",
    "index_list = df_inconsistentes_UTI.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e UTI está nula ou 9\r\n",
    "df.loc[df.index[index_list],'PREENCHER_UTI'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.4 - Identifica Casos de UTI sem Data de Entrada\r\n",
    "Nos registros onde UTI = 1 (Sim) e a data de entrada na UTI esta nula, será escrito \"Sim\" na coluna 'PREENCHER_DATA_ENTRADA_UTI'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# UTI = 1 e sem data de entrada UTI\r\n",
    "'PREENCHER_DATA_ENTRADA_UTI'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde existe homem classificado como puérpera \r\n",
    "index_list = df.loc[df['UTI'] ==1].loc[df['DT_ENTUTI'].isna(),'PREENCHER_DATA_ENTRADA_UTI'].index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_DATA_ENTRADA_UTI onde não existe data de entrada UTI\r\n",
    "df.loc[df.index[index_list],'PREENCHER_DATA_ENTRADA_UTI'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.5 - Identifica Casos de UTI sem Data de Saída, com mais de 6 meses de primeiros sintomas\r\n",
    "Nos registros com mais de 6 meses da data de primeiros sintomas onde UTI = 1 (Sim) e a data de saída na UTI esta nula, será escrito \"Sim\" na coluna 'PREENCHER_DATA_SAIDA_UTI'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# UTI = 1 e sem data de saída UTI\r\n",
    "'PREENCHER_DATA_SAIDA_UTI'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde existe homem classificado como puérpera \r\n",
    "df_UTI_sem_data_saida = df.loc[df['UTI'] ==1].loc[df['DT_SAIDUTI'].isna()]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_UTI_sem_data_saida \r\n",
    "df_UTI_sem_data_saida['SUBTRACAO_MES_ATUAL'] = 0\r\n",
    "\r\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_UTI_sem_data_saida e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\r\n",
    "for x in df_UTI_sem_data_saida.index:\r\n",
    "    df_UTI_sem_data_saida['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_UTI_sem_data_saida['DT_SIN_PRI'][x]).days/30\r\n",
    "\r\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\r\n",
    "df_UTI_sem_data_saida = df_UTI_sem_data_saida.loc[df_UTI_sem_data_saida['SUBTRACAO_MES_ATUAL'] >= 6]\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e UTI está nula ou 9\r\n",
    "index_list = df_UTI_sem_data_saida.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e UTI está nula ou 9\r\n",
    "df.loc[df.index[index_list],'PREENCHER_DATA_SAIDA_UTI'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.6 - Identificar casos de Óbitos sem hospitalização\r\n",
    "Nos registros onde o pacienteveio a óbito e classificação não para Hospitalização, será escrito \"Sim\" na coluna 'OBITOS_SEM_HOSPITALIZACAO'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# Óbitos sem hospitalização\r\n",
    "'OBITOS_SEM_HOSPITALIZACAO'\r\n",
    "\r\n",
    "# Cria uma planilha somente com os registros de não hospitalizados\r\n",
    "df_nao_hospitalizacao_obito = df.loc[df['HOSPITAL']==2]\r\n",
    "\r\n",
    "#Cria uma planilha de não hospitalizados e vieram a óbito por covid\r\n",
    "df_nao_hospitalizacao_obito1 = df_nao_hospitalizacao_obito.loc[df['EVOLUCAO']==2]\r\n",
    "\r\n",
    "#Cria uma planilha de não hospitalizados e vieram a óbito por outras causas\r\n",
    "df_nao_hospitalizacao_obito2 = df_nao_hospitalizacao_obito.loc[df['EVOLUCAO']==3]\r\n",
    "\r\n",
    "# Junta as colunas criadas a cima\r\n",
    "df_nao_hospitalizacao_obito = pd.concat([df_nao_hospitalizacao_obito1, df_nao_hospitalizacao_obito2,])\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e UTI está nula ou 9\r\n",
    "index_list = df_nao_hospitalizacao_obito.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna OBITOS_SEM_HOSPITALIZACAO nos registros com mais de 6 meses e UTI está nula ou 9\r\n",
    "df.loc[df.index[index_list],'OBITOS_SEM_HOSPITALIZACAO'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.7 - Identifica Casos onde o Critério de finalização é 4 e o resultado da tomografia é diferente de 1 ou 5\r\n",
    "Nos registros o critério de finalização é 4 e o resultado da tomografia é diferente de 1 ou 5, será escrito \"Sim\" na coluna 'CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# CRITERIO = 4 e TOMO_RES diferente de 1 ou 5\r\n",
    "'CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde critério = 4, TOMO_RES diferente de 1 e 5\r\n",
    "index_list = df.loc[df['CRITERIO'] ==4].loc[df['TOMO_RES']!=1].loc[df['TOMO_RES']!=5].index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5 onde CRITERIO = 4 e TOMO_RES diferente de 1 ou 5\r\n",
    "df.loc[df.index[index_list],'CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5'] = 'Sim'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.8 - Identifica os casos onde possui hospitalização = 9 (ignorada) ou nula\r\n",
    "Nos registros onde onde possui hospitalização = 9 (ignorada) ou nula, será escrito \"Sim\" na coluna 'PREENCHER_HOSPITALIZACAO'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# HOSPITAL = ignorado ou vazio\r\n",
    "'PREENCHER_HOSPITALIZACAO'\r\n",
    "\r\n",
    "# CRIA UMA PLANILHA COM OS REGISTROS ONDE HOSPITAL = 9 OU NULO\r\n",
    "df_sem_hospitalizacao = pd.concat([df[df['HOSPITAL'].isna()],df.loc[df['HOSPITAL'] == 9]])\r\n",
    "\r\n",
    "# CRIA UMA lista COM OS index onde os REGISTROS HOSPITAL = 9 OU NULO\r\n",
    "index_list = df_sem_hospitalizacao.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_HOSPITALIZACAO onde HOSPITAL = ignorado ou vazio\r\n",
    "df.loc[df.index[index_list],'PREENCHER_HOSPITALIZACAO'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.9 - Identifica casos onde a pessoa foi curada e não possui hospitalização\r\n",
    "Nos registros onde a pessoa foi curada e não possui hospitalização, será escrito \"Sim\" na coluna 'CURA_SEM_HOSPITALIZACAO'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# HOSPITAL = 2 e EVOLUCAO = 1\r\n",
    "'CURA_SEM_HOSPITALIZACAO'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde critério = 4, TOMO_RES diferente de 1 e 5\r\n",
    "index_list = df.loc[df['HOSPITAL'] == 2].loc[df['EVOLUCAO']==1].index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna CURA_SEM_HOSPITALIZACAO onde HOSPITAL = 2 e EVOLUCAO = 1\r\n",
    "df.loc[df.index[index_list],'CURA_SEM_HOSPITALIZACAO'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.10 - Identifica Registros com valor 9 (ignorado) ou nulo em Suporte ventilatório\r\n",
    "Nos registros com valor 9 (ignorado) ou nulo em Suporte ventilatório, será escrito \"Sim\" na coluna 'PREENCHER_SUPORT_VEN'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# SUPORTE_VEN = 9 ou NAN\r\n",
    "'PREENCHER_SUPORT_VEN'\r\n",
    "\r\n",
    "# Cria uma planilha onde SUPORTE_VEN = 9 ou NAN\r\n",
    "df_sem_suporte_vent = pd.concat([df[df['SUPORT_VEN'].isna()],df.loc[df['SUPORT_VEN'] == 9]])\r\n",
    "\r\n",
    "# Cria uma lista com os index onde SUPORTE_VEN = 9 ou NAN\r\n",
    "index_list = df_sem_suporte_vent.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna CURA_SEM_HOSPITALIZACAO onde SUPORTE_VEN = 9 ou NAN\r\n",
    "df.loc[df.index[index_list],'PREENCHER_HOSPITALIZACAO'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.11 - Identifica registros com Classificação final = 3 e CLASSI_OUT nula\r\n",
    "Nos registros com Classificação final = 3 e CLASSI_OUT nula, será escrito \"Sim\" na coluna 'PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# CLASSI_FIN = 3 E CLASSI_OUT = NAN\r\n",
    "'PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde CLASSI_FIN = 3 E CLASSI_OUT = NAN\r\n",
    "index_list = df.loc[df['CLASSI_FIN'] == 3].loc[df['CLASSI_OUT'].isna()].index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3 onde CLASSI_FIN = 3 E CLASSI_OUT = NAN\r\n",
    "df.loc[df.index[index_list],'PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.12 - Identifica registros com Classificação final = 5, Evolução = 2 e Critério = 3\r\n",
    "Nos registros onde Classificação final = 5, Evolução = 2 e Critério = 3, será escrito \"Sim\" na coluna 'CLASSI_FIN_5_EVOLUCAO_2_E_CRITERIO_3'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# CLASSI_FIN = 5 EVOLUCAO = 2 E CRITERIO = 3\r\n",
    "'CLASSI_FIN_5_EVOLUCAO_2_E_CRITERIO_3'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde CLASSI_FIN = 5 EVOLUCAO = 2 E CRITERIO = 3\r\n",
    "index_list = df.loc[df['CLASSI_FIN'] == 5].loc[df['EVOLUCAO'] == 2].loc[df['CRITERIO'] == 3].index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3 onde CLASSI_FIN = 5 E EVOLUCAO = 2 E CRITERIO = 3\r\n",
    "df.loc[df.index[index_list],'CLASSI_FIN_5_EVOLUCAO_2_E_CRITERIO_3'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.13 - Identifica registros com data de encerrados e sem Classificação final, Critério de encerramento, Evolução ou data de Evolução\r\n",
    "Nos registros com data de encerrados e sem Classificação final, Critério de encerramento, Evolução ou data de Evolução, será escrito o que falta prencher na coluna 'ENCERRADOS_IMCOMPLETOS'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "'ENCERRADOS_IMCOMPLETOS'\r\n",
    "\r\n",
    "# CRIA UMA PLANILHA df_encerrados_incompletos COM REGISTROS NÃO NULOS EM DT_ENCERRA\r\n",
    "df_encerrados_incompletos = df[df['DT_ENCERRA'].notnull()]\r\n",
    "\r\n",
    "# ADICIONA 0 NA COLUNA ENCERRADOS_IMCOMPLETOS\r\n",
    "df_encerrados_incompletos['ENCERRADOS_IMCOMPLETOS'] = 0 \r\n",
    "\r\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS Preencher CLASSI_FIN SE CLASSI_FIN ESTIVER NULO\r\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['CLASSI_FIN'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher CLASSI_FIN'\r\n",
    "\r\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS 'Preencher CRITERIO' SE CRITERIO ESTIVER NULO\r\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['CRITERIO'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher CRITERIO'\r\n",
    "\r\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS 'Preencher EVOLUCAO' SE EVOLUCAO ESTIVER NULO\r\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['EVOLUCAO'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher EVOLUCAO'\r\n",
    "\r\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS 'Preencher DT_EVOLUCA' SE DT_EVOLUCA ESTIVER NULO\r\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['DT_EVOLUCA'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher DT_EVOLUCA'   \r\n",
    "\r\n",
    "# Deixa somente os registros onde DT_ENCERRA não é nulo e tem ao menos um dos campos (75,76,77 ou 78) nulos\r\n",
    "df_encerrados_incompletos = df_encerrados_incompletos.loc[df_encerrados_incompletos['ENCERRADOS_IMCOMPLETOS']!=0]\r\n",
    "\r\n",
    "# Cria uma lista com os index de df_encerrados_incompletos\r\n",
    "index_list = df_encerrados_incompletos.index\r\n",
    "\r\n",
    "# Escreve o critério na coluna ENCERRADOS_IMCOMPLETOS nos REGISTROS NÃO NULOS EM DT_ENCERRA e sem critérios\r\n",
    "df.loc[df.index[index_list],'ENCERRADOS_IMCOMPLETOS'] = df_encerrados_incompletos['ENCERRADOS_IMCOMPLETOS']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.14 - Identifica registros com mais de 6 meses da data de início dos primeiros sintomas e sem data de encerramento\r\n",
    "Nos registros com mais de 6 meses da data de início dos primeiros sintomas e sem data de encerramento, será escrito \"Sim\" na coluna 'PREENCHER_DT_ENCERRA'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# 79 = nan\r\n",
    "'PREENCHER_DT_ENCERRA'\r\n",
    "\r\n",
    "# CRIA UMA PLANILHA df_sem_dt_encerramento COM VALORES ONDE DT_ENCERRA É NULA\r\n",
    "df_sem_dt_encerramento = df[df['DT_ENCERRA'].isna()]\r\n",
    "\r\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_sem_dt_encerramento \r\n",
    "df_sem_dt_encerramento['SUBTRACAO_MES_ATUAL'] = 0\r\n",
    "\r\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_sem_dt_encerramento e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\r\n",
    "for x in df_sem_dt_encerramento.index:\r\n",
    "    df_sem_dt_encerramento['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_sem_dt_encerramento['DT_SIN_PRI'][x]).days/30\r\n",
    "\r\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\r\n",
    "df_sem_dt_encerramento = df_sem_dt_encerramento.loc[df_sem_dt_encerramento['SUBTRACAO_MES_ATUAL'] >= 6]\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e 79 = nan\r\n",
    "index_list = df_sem_dt_encerramento.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e 79 = nan\r\n",
    "df.loc[df.index[index_list],'PREENCHER_DT_ENCERRA'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.15 - Identifica registros com mais de 6 meses da data de início dos primeiros sintomas e sem classificação final\r\n",
    "Nos registros com mais de 6 meses da data de início dos primeiros sintomas e sem classificação final, será escrito \"Sim\" na coluna 'PREENCHER_CLASSI_FIN'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# 75= nan\r\n",
    "'PREENCHER_CLASSI_FIN'\r\n",
    "\r\n",
    "# CRIA UMA PLANILHA df_sem_classi_fim COM VALORES ONDE DT_ENCERRA É NULA\r\n",
    "df_sem_classi_fim = df[df['CLASSI_FIN'].isna()]\r\n",
    "\r\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_sem_classi_fim \r\n",
    "df_sem_classi_fim['SUBTRACAO_MES_ATUAL'] = 0\r\n",
    "\r\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_sem_classi_fim e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\r\n",
    "for x in df_sem_classi_fim.index:\r\n",
    "    df_sem_classi_fim['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_sem_classi_fim['DT_SIN_PRI'][x]).days/30\r\n",
    "\r\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\r\n",
    "df_sem_classi_fim = df_sem_classi_fim.loc[df_sem_classi_fim['SUBTRACAO_MES_ATUAL'] >= 6]\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses 75= nan\r\n",
    "index_list = df_sem_classi_fim.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e 75= nan\r\n",
    "df.loc[df.index[index_list],'PREENCHER_CLASSI_FIN'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.16 - Identifica registros com mais de 6 meses da data de início dos primeiros sintomas e sem EVOLUÇÂO (nula)\r\n",
    "Nos registros com mais de 6 meses da data de início dos primeiros sintomas e sem EVOLUÇÂO (nula), será escrito \"Sim\" na coluna 'PREENCHER_EVOLUCAO'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# 77 = NAN\r\n",
    "'PREENCHER_EVOLUCAO'\r\n",
    "\r\n",
    "# CRIA UMA PLANILHA df_sem_evolucao COM VALORES ONDE DT_ENCERRA É NULA\r\n",
    "df_sem_evolucao = df[df['EVOLUCAO'].isna()]\r\n",
    "\r\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_sem_evolucao \r\n",
    "df_sem_evolucao['SUBTRACAO_MES_ATUAL'] = 0\r\n",
    "\r\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_sem_evolucao e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\r\n",
    "for x in df_sem_evolucao.index:\r\n",
    "    df_sem_evolucao['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_sem_evolucao['DT_SIN_PRI'][x]).days/30\r\n",
    "\r\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\r\n",
    "df_sem_evolucao = df_sem_evolucao.loc[df_sem_evolucao['SUBTRACAO_MES_ATUAL'] >= 6]\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e 77 = NAN\r\n",
    "index_list = df_sem_evolucao.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e 77 = NAN\r\n",
    "df.loc[df.index[index_list],'PREENCHER_EVOLUCAO'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.17 - Identifica registros com Classificação Final = 4 e critério = 2 ou 4\r\n",
    "Nos registros com Classificação Final = 4 e critério = 2 ou 4, será escrito \"Sim\" na coluna 'CLASSI_FIN_4_CRITERIO_2_OU_4'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# 75 = 4 E 76 = 2 OU 4\r\n",
    "'CLASSI_FIN_4_CRITERIO_2_OU_4'\r\n",
    "\r\n",
    "# Cria uma planilha classi_fin4_criteirio_2_ou_4 com os casos onde classi_fin é 4\r\n",
    "classi_fin4_criteirio_2_ou_4 = df.loc[df['CLASSI_FIN']==4]\r\n",
    "\r\n",
    "# CRIA UMA PLANILHA classi_fin4_criteirio_2 ONDE CLASSI_FIN É 4 E CRITERIO = 2\r\n",
    "classi_fin4_criteirio_2 = classi_fin4_criteirio_2_ou_4.loc[classi_fin4_criteirio_2_ou_4['CRITERIO']==2]\r\n",
    "\r\n",
    "# CRIA UMA PLANILHA classi_fin4_criteirio_4 ONDE CLASSI_FIN É 4 E CRITERIO = 4\r\n",
    "classi_fin4_criteirio_4 = classi_fin4_criteirio_2_ou_4.loc[classi_fin4_criteirio_2_ou_4['CRITERIO']==4]\r\n",
    "\r\n",
    "# jUNTA AS PLANILHAS classi_fin4_criteirio_2 E classi_fin4_criteirio_4 NA PLANILHA classi_fin4_criteirio_2_ou_4\r\n",
    "classi_fin4_criteirio_2_ou_4 = pd.concat([classi_fin4_criteirio_2,classi_fin4_criteirio_4])\r\n",
    "\r\n",
    "# Cria uma lista com os index nos registros  75 = 4 E 76 = 2 OU 4\r\n",
    "index_list = classi_fin4_criteirio_2_ou_4.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros  75 = 4 E 76 = 2 OU 4\r\n",
    "df.loc[df.index[index_list],'CLASSI_FIN_4_CRITERIO_2_OU_4'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.18 - Identifica os registros que não possuem sintomas\r\n",
    "Nos registros que não possuem sintomas, será escrito \"Sim\" na coluna 'SEM_SINTOMA'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# Registros sem nenhum sintma\r\n",
    "'SEM_SINTOMA'\r\n",
    "\r\n",
    "# CRIA UMA LISTA COM as colunas dos sintomas\r\n",
    "colunas_sintomas = ['FEBRE','TOSSE','GARGANTA','DISPNEIA','DESC_RESP','SATURACAO','DIARREIA','VOMITO','DOR_ABD','FADIGA','PERD_OLFT','PERD_PALA','OUTRO_SIN','OUTRO_DES']\r\n",
    "\r\n",
    "# Cria uma planilha df_sem_sintomas com os valores de df\r\n",
    "df_sem_sintomas = df\r\n",
    "\r\n",
    "# Aloca na coluna SEM_SINTOMA a quantidade de sintomas nulos de cada linha\r\n",
    "df_sem_sintomas['SOMA'] = df_sem_sintomas[colunas_sintomas].isnull().sum(axis=1)\r\n",
    "\r\n",
    "# Deixa na planilha df_sem_sintomas somente os registro onde a coluna SEM_SINTOMA = 14 (quantidade de colunas de sintomas)\r\n",
    "df_sem_sintomas = df_sem_sintomas.loc[df_sem_sintomas['SOMA'] == 14]\r\n",
    "\r\n",
    "# Cria uma lista com os index dos registros sem sintomas\r\n",
    "index_list = df_sem_sintomas.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros sem nenhum sintma\r\n",
    "df.loc[df.index[index_list],'SEM_SINTOMA'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.19 - Identifica os registros classificados como SRAG Laboratorial mas não possuem informações dos exames\r\n",
    "Nos registros classificados como SRAG Laboratorial mas não possuem informações dos exames, será escrito \"Preencher colunas PCR_SARS2, AN_SARS2, RES_IGG ou RES_IGM\" na coluna 'SRAG_LABORATORIAL_ERRADO'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# 75 = 5 E 76 = 1 E PCR_SARS2 e AN_SARS2 = NAN e RES_IGG e RES_IGM = NAN e !=1\r\n",
    "\r\n",
    "'SRAG_LABORATORIAL_ERRADO'\r\n",
    "\r\n",
    "# Cria uma lista com os index onde existe 75 = 5 E 76 = 1 E PCR_SARS2 e AN_SARS2 = NAN e RES_IGG e RES_IGM = NAN e !=1\r\n",
    "index_list = df.loc[df['CLASSI_FIN'] ==5].loc[df['CRITERIO']==1].loc[df['PCR_SARS2'].isna()].loc[df['AN_SARS2'].isna()].loc[df['RES_IGG'].isna()].loc[df['RES_IGM'].isna()].index\r\n",
    "\r\n",
    "# Escreve 'Preencher colunas PCR_SARS2, AN_SARS2, RES_IGG ou RES_IGM' na coluna HOMEM_PUERPERO onde existe homeme classificado como puérpero\r\n",
    "df.loc[df.index[index_list],'SRAG_LABORATORIAL_ERRADO'] = 'Preencher colunas PCR_SARS2, AN_SARS2, RES_IGG ou RES_IGM'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1.20 - Identifica os registros classificados como influenza e possuem exames resultados para Covid-19\r\n",
    "Nos registros classificados como influenza e possuem exames resultados para Covid-19, será escrito \"Sim\" na coluna 'CLASSI_FIN_1_COVID_1'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# Campo 75 CLASSI_FIN influenza = 1 --> PCR_SARS2 ou AN_SARS2 = 1 ou RES_IGG ou RES_IGM = 1\r\n",
    "\r\n",
    "'CLASSI_FIN_1_COVID_1'\r\n",
    "\r\n",
    "# Cria uma planilha df_inflenza_e_covid com os registros onde CLASSI_FIN = 1\r\n",
    "df_inflenza_e_covid = df.loc[df['CLASSI_FIN']==1]\r\n",
    "\r\n",
    "# Cria uma planilha df_inflenza_e_covid_PCR_SARS2 com os registros de df_inflenza_e_covid onde PCR_SARS2 = 1\r\n",
    "df_inflenza_e_covid_PCR_SARS2 = df_inflenza_e_covid.loc[df_inflenza_e_covid['PCR_SARS2']==1]\r\n",
    "\r\n",
    "# Cria uma planilha df_inflenza_e_covid_AN_SARS2 com os registros de df_inflenza_e_covid onde AN_SARS2 = 1\r\n",
    "df_inflenza_e_covid_AN_SARS2 = df_inflenza_e_covid.loc[df_inflenza_e_covid['AN_SARS2']==1]\r\n",
    "\r\n",
    "# Cria uma planilha df_inflenza_e_covid_RES_IGG com os registros de df_inflenza_e_covid onde RES_IGG = 1\r\n",
    "df_inflenza_e_covid_RES_IGG = df_inflenza_e_covid.loc[df_inflenza_e_covid['RES_IGG']==1]\r\n",
    "\r\n",
    "# Cria uma planilha df_inflenza_e_covid_RES_IGM com os registros de df_inflenza_e_covid onde RES_IGM = 1\r\n",
    "df_inflenza_e_covid_RES_IGM = df_inflenza_e_covid.loc[df_inflenza_e_covid['RES_IGM']==1]\r\n",
    "\r\n",
    "# Junta as 4 planilhas criadas a cima e aloca na planilha df_inflenza_e_covid\r\n",
    "df_inflenza_e_covid = pd.concat([df_inflenza_e_covid_PCR_SARS2, df_inflenza_e_covid_AN_SARS2, df_inflenza_e_covid_RES_IGG, df_inflenza_e_covid_RES_IGM])\r\n",
    "\r\n",
    "# Cria uma lista com os index dos registros 75 CLASSI_FIN influenza = 1 --> PCR_SARS2 ou AN_SARS2 = 1 ou RES_IGG ou RES_IGM = 1\r\n",
    "index_list = df_inflenza_e_covid.index\r\n",
    "\r\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros 75 CLASSI_FIN influenza = 1 --> PCR_SARS2 ou AN_SARS2 = 1 ou RES_IGG ou RES_IGM = 1\r\n",
    "df.loc[df.index[index_list],'CLASSI_FIN_1_COVID_1'] = 'Sim'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.2.1 Salvar Planilhas de inconsistências"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# Define quais serão as colunas de erros\r\n",
    "colunas_finais = ['ID_UNIDADE','HOMEM_PUERPERO', 'HOMEM_GRAVIDO', 'PREENCHER_UTI', 'PREENCHER_DATA_ENTRADA_UTI', 'PREENCHER_DATA_SAIDA_UTI', \r\n",
    "'OBITOS_SEM_HOSPITALIZACAO','CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5', 'PREENCHER_HOSPITALIZACAO', 'CURA_SEM_HOSPITALIZACAO', \r\n",
    "'PREENCHER_SUPORT_VEN', 'PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3', 'CLASSI_FIN_5_EVOLUCAO_2_E_CRITERIO_3', 'ENCERRADOS_IMCOMPLETOS', \r\n",
    "'PREENCHER_DT_ENCERRA', 'PREENCHER_CLASSI_FIN', 'PREENCHER_EVOLUCAO', 'CLASSI_FIN_4_CRITERIO_2_OU_4', 'SEM_SINTOMA', 'SRAG_LABORATORIAL_ERRADO', 'CLASSI_FIN_1_COVID_1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# transforma a coluna NU_NOTIFIC em index\r\n",
    "df.set_index('NU_NOTIFIC', inplace = True)\r\n",
    "\r\n",
    "# Substitui os valores zeros por nulos\r\n",
    "df.replace(0, np.nan, inplace=True)\r\n",
    "\r\n",
    "# Aloca na coluna ERROS a quantidade de ERROS de cada linha\r\n",
    "df['ERROS'] = df[colunas_erros].isnull().sum(axis=1)\r\n",
    "\r\n",
    "# Deixa na planilha df somente os registros que possuem ao menos 1 erro\r\n",
    "df = df.loc[df['ERROS'] != 20]\r\n",
    "\r\n",
    "# Deixa somente as colunas de erros e de ID_UNIDADE\r\n",
    "df = df[colunas_finais]\r\n",
    "\r\n",
    "# Substitui os valores nulos por '--'\r\n",
    "df.replace(np.nan, '--', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "# Salva a planilha com o nome dos hospitais e os erros\r\n",
    "df.to_excel(\"bases/erros/todos_erros.xlsx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.2.2 Salvar Planilhas de inconsistências por Hospital\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "# Cria uma lista chamada hospitais com todos os nomes dos hospitais que aparecem na planilha df\r\n",
    "hospitais = df.ID_UNIDADE.unique()\r\n",
    "\r\n",
    "# Cria uma variável rota com a rota onde a planilha será salva, caso deseje musar isto, alterar aqui\r\n",
    "rota = 'bases/erros/erros por hospitais/'\r\n",
    "\r\n",
    "# Cria uma variável extencao que serve para definir a extensão da planilha a ser salva\r\n",
    "extencao = '.xlsx'\r\n",
    "\r\n",
    "# Cria um loop que irá ocorrer a quantidade de hospitais na planilha df\r\n",
    "for x in range(hospitais.shape[0]):\r\n",
    "    # Cria uma variável nome_hospital com o nome do hospital que está sendo percorrido pela lista\r\n",
    "    nome_hospital = hospitais[x]\r\n",
    "\r\n",
    "    # Cria uma variável salvar que junta a rota, nome do hospital e a extensão Ex: bases/planilha dos hospitais apagar/HRAN.xlsx\r\n",
    "    salvar = rota+nome_hospital+extencao\r\n",
    "\r\n",
    "    # Na posição da lista que o loop está percorrendo, é feito um df somente com os registros de repetidos a serem apagados do hospital e\r\n",
    "    # salva uma planilha com o nome do hospital na rota criada em rota\r\n",
    "    df_hospital = df.loc[df['ID_UNIDADE']==hospitais[x]]\r\n",
    "\r\n",
    "    # troca os 2 tracinhos por um valor nulo\r\n",
    "    df_hospital.replace('--', np.nan, inplace=True)\r\n",
    "\r\n",
    "    # Apaga as colunas onde todos os valores são nulos\r\n",
    "    df_hospital.dropna(axis=1, how='all', inplace = True)\r\n",
    "\r\n",
    "    # Salva a planilha em excel \r\n",
    "    df_hospital.to_excel(salvar)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 Envio de e-mails "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "import smtplib\r\n",
    "from email.mime.multipart import MIMEMultipart\r\n",
    "from email.mime.text import MIMEText\r\n",
    "from email.mime.base import MIMEBase\r\n",
    "from email import encoders\r\n",
    "import ast"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.1 - Enviar e-mails com casos Duplicados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "# Lê o arquivo com as duplicidades a serem apagadas e aloca na variável hospitais\r\n",
    "hospitais = pd.read_excel(\"bases/duplicidades/duplicidades_apagadas.xlsx\")\r\n",
    "\r\n",
    "# Transforma a variável hospitais em um array que contém os nomes dos hospitais presentes na planilha de duplicidades a serem apagadas\r\n",
    "hospitais = hospitais.ID_UNIDADE.unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# É necessário que exista, na mesma pasta do código) um arquivo 'lista_emails.txt' contento um dicionário com o nome dos hospitais (como digitado nas planilhas) e o e-mail do hospital\r\n",
    "# Instancia o arquivo com os emails dos Hospitais\r\n",
    "file  = open(\"lista_emails.txt\", 'r')\r\n",
    "\r\n",
    "# Lê o arquivo de emails e adiciona na variável contents\r\n",
    "contents = file.read()\r\n",
    "\r\n",
    "# Cria um dicionário chamado emails, com o nome dos hospitais e os emails - o que está na lista_emails.txt\r\n",
    "emails = ast.literal_eval(contents)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cria uma variável rota com a rota onde a planilha será salva, caso deseje musar isto, alterar aqui\r\n",
    "rota = 'bases/duplicidades/duplicidades por hospitais/'\r\n",
    "\r\n",
    "# Cria uma variável extencao que serve para definir a extensão da planilha a ser salva\r\n",
    "extencao = '.xlsx'\r\n",
    "\r\n",
    "username = 'apcs.1502@gmail.com'\r\n",
    "password = 'fomgnsjujrxcrfpc'\r\n",
    "mail_from  = 'apcs.1502@gmail.com'\r\n",
    "\r\n",
    "título_email = 'Registros duplicados - '\r\n",
    "corpo_email = 'Segue em anexo os registros que identificamos com duplicados, por gentileza apague todos do sistema.'\r\n",
    "\r\n",
    "\r\n",
    "# Cria uma lista com todos os e-mails presentes de hospitais na lista de e-mails - evita que de erro ao tentar enviar um e-mail para um hospital que não esteja na lista\r\n",
    "lista_todos_emails = list()\r\n",
    "for i in emails.keys():\r\n",
    "    lista_todos_emails.append(i)\r\n",
    "\r\n",
    "\r\n",
    "# Cria um loop que irá ocorrer a quantidade de hospitais na planilha df_repetidos_apagados_hospitais\r\n",
    "for x in range(hospitais.shape[0]):\r\n",
    "    # Cria uma variável nome_hospital com o nome do hospital que está sendo percorrido pela lista\r\n",
    "    nome_hospital = hospitais[x]\r\n",
    "\r\n",
    "    # Verifica se o nome do hospital tem e-mail\r\n",
    "    if nome_hospital in lista_todos_emails:\r\n",
    "\r\n",
    "        # Cria uma variável salvar que junta a rota, nome do hospital e a extensão Ex: bases/planilha dos hospitais apagar/HRAN.xlsx\r\n",
    "        salvar = rota+nome_hospital+extencao\r\n",
    "\r\n",
    "        # Seleciona pra qual e-mail a mensagem e a planilha serão enviados\r\n",
    "        mail_to = emails[nome_hospital]\r\n",
    "        # Título do e-mail\r\n",
    "        mail_subject = título_email+nome_hospital\r\n",
    "        # Corpo do e-mail\r\n",
    "        mail_body = 'Favor apagar no sistema SIVEP o registro dos pacientes na planilha em anexo'\r\n",
    "\r\n",
    "        # Arquivo a ser enviado (passa a rota do arquivo de cada hospital)\r\n",
    "        mail_attachment=salvar\r\n",
    "        # Nome e extensão do arquivo\r\n",
    "        mail_attachment_name=nome_hospital+extencao\r\n",
    "\r\n",
    "        mimemsg = MIMEMultipart()\r\n",
    "        # seleciona qual e-mail vai enviar a mensagem\r\n",
    "        mimemsg['From']=mail_from\r\n",
    "        # Seleciona o e-mail destino\r\n",
    "        mimemsg['To']=mail_to\r\n",
    "        # Define o Título do e-mail\r\n",
    "        mimemsg['Subject']=mail_subject\r\n",
    "        # Define a mensagem do e-mail\r\n",
    "        mimemsg.attach(MIMEText(mail_body, 'plain'))\r\n",
    "\r\n",
    "        # Enviar e-mail - Não alterar esta parte de código\r\n",
    "        with open(mail_attachment, \"rb\") as attachment:\r\n",
    "            mimefile = MIMEBase('application', 'octet-stream')\r\n",
    "            mimefile.set_payload((attachment).read())\r\n",
    "            encoders.encode_base64(mimefile)\r\n",
    "            mimefile.add_header('Content-Disposition', \"attachment; filename= %s\" % mail_attachment_name)\r\n",
    "            mimemsg.attach(mimefile)\r\n",
    "            connection = smtplib.SMTP(host='smtp.gmail.com', port=587)\r\n",
    "            connection.starttls()\r\n",
    "            connection.login(username,password)\r\n",
    "            connection.send_message(mimemsg)\r\n",
    "            connection.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.2 - Enviar e-mails com registros inconsistentes ou incoompletos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# Lê o arquivo com as duplicidades a serem apagadas e aloca na variável hospitais\r\n",
    "hospitais = pd.read_excel(\"bases/erros/todos_erros.xlsx\")\r\n",
    "\r\n",
    "# Transforma a variável hospitais em um array que contém os nomes dos hospitais presentes na planilha de duplicidades a serem apagadas\r\n",
    "hospitais = hospitais.ID_UNIDADE.unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cria uma variável rota com a rota onde a planilha será salva, caso deseje musar isto, alterar aqui\r\n",
    "rota = 'bases/erros/erros por hospitais/'\r\n",
    "\r\n",
    "# Cria uma variável extencao que serve para definir a extensão da planilha a ser salva\r\n",
    "extencao = '.xlsx'\r\n",
    "\r\n",
    "username = 'apcs.1502@gmail.com'\r\n",
    "password = 'fomgnsjujrxcrfpc'\r\n",
    "mail_from  = 'apcs.1502@gmail.com'\r\n",
    "\r\n",
    "título_email = 'Registros duplicados - '\r\n",
    "corpo_email = 'Segue em anexo os registros que identificamos com duplicados, por gentileza apague todos do sistema.'\r\n",
    "\r\n",
    "# Cria uma lista com todos os e-mails presentes de hospitais na lista de e-mails - evita que de erro ao tentar enviar um e-mail para um hospital que não esteja na lista\r\n",
    "lista_todos_emails = list()\r\n",
    "for i in emails.keys():\r\n",
    "    lista_todos_emails.append(i)\r\n",
    "\r\n",
    "\r\n",
    "# Cria um loop que irá ocorrer a quantidade de hospitais na planilha df_repetidos_apagados_hospitais\r\n",
    "for x in range(hospitais.shape[0]):\r\n",
    "    # Cria uma variável nome_hospital com o nome do hospital que está sendo percorrido pela lista\r\n",
    "    nome_hospital = hospitais[x]\r\n",
    "\r\n",
    "    # Verifica se o nome do hospital tem e-mail\r\n",
    "    if nome_hospital in lista_todos_emails:\r\n",
    "    \r\n",
    "        # Cria uma variável salvar que junta a rota, nome do hospital e a extensão Ex: bases/planilha dos hospitais apagar/HRAN.xlsx\r\n",
    "        salvar = rota+nome_hospital+extencao\r\n",
    "\r\n",
    "        # Seleciona pra qual e-mail a mensagem e a planilha serão enviados\r\n",
    "        mail_to = emails[nome_hospital]\r\n",
    "        # Título do e-mail\r\n",
    "        mail_subject = título_email+nome_hospital\r\n",
    "        # Corpo do e-mail\r\n",
    "        mail_body = 'Favor Corrigir os registros que seguem em anexo nas planilhas.'\r\n",
    "\r\n",
    "        # Arquivo a ser enviado (passa a rota do arquivo de cada hospital)\r\n",
    "        mail_attachment=salvar\r\n",
    "        # Nome e extensão do arquivo\r\n",
    "        mail_attachment_name=nome_hospital+extencao\r\n",
    "\r\n",
    "        mimemsg = MIMEMultipart()\r\n",
    "        # seleciona qual e-mail vai enviar a mensagem\r\n",
    "        mimemsg['From']=mail_from\r\n",
    "        # Seleciona o e-mail destino\r\n",
    "        mimemsg['To']=mail_to\r\n",
    "        # Define o Título do e-mail\r\n",
    "        mimemsg['Subject']=mail_subject\r\n",
    "        # Define a mensagem do e-mail\r\n",
    "        mimemsg.attach(MIMEText(mail_body, 'plain'))\r\n",
    "\r\n",
    "        # Enviar e-mail - Não alterar esta parte de código\r\n",
    "        with open(mail_attachment, \"rb\") as attachment:\r\n",
    "            mimefile = MIMEBase('application', 'octet-stream')\r\n",
    "            mimefile.set_payload((attachment).read())\r\n",
    "            encoders.encode_base64(mimefile)\r\n",
    "            mimefile.add_header('Content-Disposition', \"attachment; filename= %s\" % mail_attachment_name)\r\n",
    "            mimemsg.attach(mimefile)\r\n",
    "            connection = smtplib.SMTP(host='smtp.gmail.com', port=587)\r\n",
    "            connection.starttls()\r\n",
    "            connection.login(username,password)\r\n",
    "            connection.send_message(mimemsg)\r\n",
    "            connection.quit()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ed9da5cbc7b86d57c325d239c73fa64a04135dc9055b44153a9f7cdf507ff419"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}