{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializ\"ando processo de qualidade\n"
     ]
    }
   ],
   "source": [
    "print('Inicializ\"ando processo de qualidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import int64\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "#!pip install elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "import elasticsearch.helpers\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from openpyxl.workbook import Workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o download da base de dados\n",
      " Download da base de dados completo\n",
      "Iniciando tratamento dos dados\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "arr = os.listdir()\n",
    "\n",
    "if 'df.xlsx' in arr:\n",
    "    print('Lendo a base de dados')\n",
    "    df = pd.read_excel('df.xlsx')\n",
    "else:\n",
    "    print('Iniciando o download da base de dados')\n",
    "    user = 'esusve-df'\n",
    "    pwd = 'Kshuciangdix'\n",
    "    index = 'srag-df'\n",
    "\n",
    "    # Define a URL com usuario e senha\n",
    "    url = 'https://' + user + ':' + pwd + '@elasticsearch-saps.saude.gov.br'\n",
    "\n",
    "    # Faz uma requisição POST com a URL definida\n",
    "    es = Elasticsearch([url], send_get_body_as='POST')\n",
    "\n",
    "    # Verifica toda a base de dados disponível\n",
    "    body={\"query\": {\"match_all\": {}}}\n",
    "\n",
    "    # Cria um documento contendo a base de dados definida pelo index\n",
    "    results = elasticsearch.helpers.scan(es, query=body, index=index)\n",
    "\n",
    "    # Cria um Data Frame chamado df, com toda a base de dados de SRAG do DF\n",
    "    df = pd.DataFrame.from_dict([document['_source'] for document in results])\n",
    "    \n",
    "    print(' Download da base de dados completo')\n",
    "\n",
    "    df.columns = df.columns.str.upper()\n",
    "\n",
    "    ordem_colunas = ['NU_NOTIFIC', 'DT_NOTIFIC', 'SEM_NOT', 'DT_SIN_PRI', 'SEM_PRI', 'SG_UF_NOT', 'ID_REGIONA', 'CO_REGIONA', 'ID_MUNICIP', 'CO_MUN_NOT', 'ID_UNIDADE',\n",
    "    'CO_UNI_NOT', 'NU_CPF', 'NM_PACIENT', 'CS_SEXO', 'DT_NASC', 'NU_IDADE_N', 'TP_IDADE', 'COD_IDADE', 'CS_GESTANT', 'CS_RACA', 'CS_ETINIA', 'CS_ESCOL_N', 'NM_MAE_PAC',\n",
    "    'NU_CEP', 'ID_PAIS', 'CO_PAIS', 'SG_UF', 'ID_RG_RESI', 'CO_RG_RESI', 'ID_MN_RESI', 'CO_MUN_RES', 'NM_BAIRRO', 'NM_LOGRADO', 'NU_NUMERO', 'NM_COMPLEM', 'NU_DDD_TEL',\n",
    "    'NU_TELEFON', 'CS_ZONA', 'SURTO_SG', 'NOSOCOMIAL', 'AVE_SUINO', 'FEBRE', 'TOSSE', 'GARGANTA', 'DISPNEIA', 'DESC_RESP', 'SATURACAO', 'DIARREIA', 'VOMITO', 'OUTRO_SIN',\n",
    "    'OUTRO_DES', 'FATOR_RISC', 'PUERPERA', 'CARDIOPATI', 'HEMATOLOGI', 'SIND_DOWN', 'HEPATICA', 'ASMA', 'DIABETES', 'NEUROLOGIC', 'PNEUMOPATI', 'IMUNODEPRE', 'RENAL',\n",
    "    'OBESIDADE', 'OBES_IMC', 'OUT_MORBI', 'MORB_DESC', 'VACINA', 'DT_UT_DOSE', 'MAE_VAC', 'DT_VAC_MAE', 'M_AMAMENTA', 'DT_DOSEUNI', 'DT_1_DOSE', 'DT_2_DOSE', 'ANTIVIRAL',\n",
    "    'TP_ANTIVIR', 'OUT_ANTIV', 'DT_ANTIVIR', 'HOSPITAL', 'DT_INTERNA', 'SG_UF_INTE', 'ID_RG_INTE', 'CO_RG_INTE', 'ID_MN_INTE', 'CO_MU_INTE', 'NM_UN_INTE', 'CO_UN_INTE',\n",
    "    'UTI', 'DT_ENTUTI', 'DT_SAIDUTI', 'SUPORT_VEN', 'RAIOX_RES', 'RAIOX_OUT', 'DT_RAIOX', 'AMOSTRA', 'DT_COLETA', 'TP_AMOSTRA', 'OUT_AMOST', 'REQUI_GAL', 'PCR_RESUL',\n",
    "    'DT_PCR', 'POS_PCRFLU', 'TP_FLU_PCR', 'PCR_FLUASU', 'FLUASU_OUT', 'PCR_FLUBLI', 'FLUBLI_OUT', 'POS_PCROUT', 'PCR_VSR', 'PCR_PARA1', 'PCR_PARA2', 'PCR_PARA3', 'PCR_PARA4',\n",
    "    'PCR_ADENO', 'PCR_METAP', 'PCR_BOCA', 'PCR_RINO', 'PCR_OUTRO', 'DS_PCR_OUT', 'LAB_PCR', 'CO_LAB_PCR', 'CLASSI_FIN', 'CLASSI_OUT', 'CRITERIO', 'EVOLUCAO', 'DT_EVOLUCA',\n",
    "    'DT_ENCERRA', 'OBSERVA', 'NOME_PROF', 'REG_PROF', 'DT_DIGITA', 'DT_ATUALIZACAO', 'HISTO_VGM', 'PAIS_VGM', 'CO_PS_VGM', 'LO_PS_VGM', 'DT_VGM', 'DT_RT_VGM', 'PCR_SARS2', \n",
    "    'PAC_COCBO', 'PAC_DSCBO', 'OUT_ANIM', 'DOR_ABD', 'FADIGA', 'PERD_OLFT', 'PERD_PALA', 'TOMO_RES', 'TOMO_OUT', 'DT_TOMO', 'TP_TES_AN', 'DT_RES_AN', 'RES_AN', 'LAB_AN', \n",
    "    'CO_LAB_AN', 'POS_AN_FLU', 'TP_FLU_AN', 'POS_AN_OUT', 'AN_SARS2', 'AN_VSR', 'AN_PARA1', 'AN_PARA2', 'AN_PARA3', 'AN_ADENO', 'AN_OUTRO', 'DS_AN_OUT', 'TP_AM_SOR', 'SOR_OUT', \n",
    "    'DT_CO_SOR', 'TP_SOR', 'OUT_SOR', 'DT_RES', 'RES_IGG', 'RES_IGM', 'RES_IGA', 'NU_DO', 'POV_CT', 'TP_POV_CT', 'TEM_CPF', 'ESTRANG', 'NU_CNS', 'VACINA_COV', 'DOSE_1_COV', \n",
    "    'NOT_CAPITAL', '@TIMESTAMP', 'RES_CAPITAL', '@VERSION', 'DOSE_2_COV', 'FAB_COV', 'LOTE_1_COV', 'LOTE_2_COV', 'FNT_IN_COV',]\n",
    "\n",
    "    \n",
    "    \n",
    "    # Deixa as colunas na Ordem \n",
    "    df = df[ordem_colunas]\n",
    "\n",
    "\n",
    "print ('Iniciando tratamento dos dados')\n",
    "\n",
    "df.to_csv('df_csv.csv', index = False, encoding='utf-8-sig')\n",
    "\n",
    "df = pd.read_csv('df_csv.csv', parse_dates=[0], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alterar os tipos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as colunas de datas\n",
    "datas = [\n",
    "'DT_NASC',\n",
    "'DT_DIGITA',\n",
    "'DT_SIN_PRI',\n",
    "'DT_INTERNA',\n",
    "'DT_ENTUTI',\n",
    "'DT_SAIDUTI',\n",
    "'DT_PCR',\n",
    "'DT_EVOLUCA',\n",
    "'DT_ENCERRA',\n",
    "'DT_COLETA',\n",
    "'DT_NOTIFIC'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = [\n",
    " 'CO_REGIONA',\n",
    " 'CS_ESCOL_N',\n",
    " 'NU_CEP',\n",
    " 'CO_RG_RESI',\n",
    " 'NU_DDD_TEL',\n",
    " 'CS_ZONA',\n",
    " 'SURTO_SG',\n",
    " 'NOSOCOMIAL',\n",
    " 'AVE_SUINO',\n",
    " 'FEBRE',\n",
    " 'TOSSE',\n",
    " 'GARGANTA',\n",
    " 'DISPNEIA',\n",
    " 'DESC_RESP',\n",
    " 'SATURACAO',\n",
    " 'DIARREIA',\n",
    " 'VOMITO',\n",
    " 'OUTRO_SIN',\n",
    " 'PUERPERA',\n",
    " 'CARDIOPATI',\n",
    " 'HEMATOLOGI',\n",
    " 'SIND_DOWN',\n",
    " 'HEPATICA',\n",
    " 'ASMA',\n",
    " 'DIABETES',\n",
    " 'NEUROLOGIC',\n",
    " 'PNEUMOPATI',\n",
    " 'IMUNODEPRE',\n",
    " 'RENAL',\n",
    " 'OBESIDADE',\n",
    " 'OBES_IMC',\n",
    " 'OUT_MORBI',\n",
    " 'VACINA',\n",
    " 'MAE_VAC',\n",
    " 'M_AMAMENTA',\n",
    " 'DT_DOSEUNI',\n",
    " 'DT_1_DOSE',\n",
    " 'DT_2_DOSE',\n",
    " 'ANTIVIRAL',\n",
    " 'TP_ANTIVIR',\n",
    " 'HOSPITAL',\n",
    " 'CO_RG_INTE',\n",
    " 'CO_MU_INTE',\n",
    " 'CO_UN_INTE',\n",
    " 'UTI',\n",
    " 'SUPORT_VEN',\n",
    " 'RAIOX_RES',\n",
    " 'AMOSTRA',\n",
    " 'TP_AMOSTRA',\n",
    " 'REQUI_GAL',\n",
    " 'PCR_RESUL',\n",
    " 'POS_PCRFLU',\n",
    " 'TP_FLU_PCR',\n",
    " 'PCR_FLUASU',\n",
    " 'FLUASU_OUT',\n",
    " 'PCR_FLUBLI',\n",
    " 'FLUBLI_OUT',\n",
    " 'POS_PCROUT',\n",
    " 'PCR_VSR',\n",
    " 'PCR_PARA1',\n",
    " 'PCR_PARA2',\n",
    " 'PCR_PARA3',\n",
    " 'PCR_PARA4',\n",
    " 'PCR_ADENO',\n",
    " 'PCR_METAP',\n",
    " 'PCR_BOCA',\n",
    " 'PCR_RINO',\n",
    " 'PCR_OUTRO',\n",
    " 'CO_LAB_PCR',\n",
    " 'CLASSI_FIN',\n",
    " 'CRITERIO',\n",
    " 'EVOLUCAO',\n",
    " 'PAIS_VGM',\n",
    " 'CO_PS_VGM',\n",
    " 'LO_PS_VGM',\n",
    " 'DT_VGM',\n",
    " 'DT_RT_VGM',\n",
    " 'PCR_SARS2',\n",
    " 'DOR_ABD',\n",
    " 'FADIGA',\n",
    " 'PERD_OLFT',\n",
    " 'PERD_PALA',\n",
    " 'RES_AN',\n",
    " 'CO_LAB_AN',\n",
    " 'POS_AN_FLU',\n",
    " 'TP_FLU_AN',\n",
    " 'POS_AN_OUT',\n",
    " 'AN_SARS2',\n",
    " 'AN_VSR',\n",
    " 'AN_PARA1',\n",
    " 'AN_PARA2',\n",
    " 'AN_PARA3',\n",
    " 'AN_ADENO',\n",
    " 'AN_OUTRO',\n",
    " 'RES_IGG',\n",
    " 'RES_IGM',\n",
    " 'RES_IGA',\n",
    " 'POV_CT',\n",
    " 'TEM_CPF',\n",
    " 'ESTRANG',\n",
    " 'NU_CNS',\n",
    " 'VACINA_COV',\n",
    " 'FNT_IN_COV',\n",
    " 'SEM_NOT',\n",
    " 'SEM_PRI',\n",
    " 'CO_MUN_NOT',\n",
    " 'CO_UNI_NOT',\n",
    " 'NU_IDADE_N',\n",
    " 'TP_IDADE',\n",
    " 'COD_IDADE',\n",
    " 'CS_GESTANT',\n",
    " 'CS_RACA',\n",
    " 'CO_PAIS',\n",
    " 'CO_MUN_RES',\n",
    " 'FATOR_RISC',\n",
    " 'HISTO_VGM',\n",
    " 'TOMO_RES',\n",
    " 'TP_TES_AN',\n",
    " 'TP_AM_SOR',\n",
    " 'TP_SOR',\n",
    " 'NU_DO'\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = [\n",
    " 'NU_NOTIFIC',\n",
    " 'SG_UF_NOT',\n",
    " 'ID_REGIONA',\n",
    " 'ID_MUNICIP',\n",
    " 'ID_UNIDADE',\n",
    " 'NU_CPF',\n",
    " 'NM_PACIENT',\n",
    " 'CS_SEXO',\n",
    " 'CS_ETINIA',\n",
    " 'NM_MAE_PAC',\n",
    " 'ID_PAIS',\n",
    " 'SG_UF',\n",
    " 'ID_RG_RESI',\n",
    " 'ID_MN_RESI',\n",
    " 'NM_BAIRRO',\n",
    " 'NM_LOGRADO',\n",
    " 'NU_NUMERO',\n",
    " 'NM_COMPLEM',\n",
    " 'NU_TELEFON',\n",
    " 'OUTRO_DES',\n",
    " 'MORB_DESC',\n",
    " 'DT_UT_DOSE',\n",
    " 'DT_VAC_MAE',\n",
    " 'OUT_ANTIV',\n",
    " 'DT_ANTIVIR',\n",
    " 'SG_UF_INTE',\n",
    " 'ID_RG_INTE',\n",
    " 'ID_MN_INTE',\n",
    " 'NM_UN_INTE',\n",
    " 'RAIOX_OUT',\n",
    " 'DT_RAIOX',\n",
    " 'OUT_AMOST',\n",
    " 'DS_PCR_OUT',\n",
    " 'LAB_PCR',\n",
    " 'CLASSI_OUT',\n",
    " 'OBSERVA',\n",
    " 'NOME_PROF',\n",
    " 'REG_PROF',\n",
    " 'PAC_COCBO',\n",
    " 'PAC_DSCBO',\n",
    " 'OUT_ANIM',\n",
    " 'TOMO_OUT',\n",
    " 'DT_TOMO',\n",
    " 'DT_RES_AN',\n",
    " 'LAB_AN',\n",
    " 'DS_AN_OUT',\n",
    " 'SOR_OUT',\n",
    " 'DT_CO_SOR',\n",
    " 'OUT_SOR',\n",
    " 'DT_RES',\n",
    " 'TP_POV_CT',\n",
    " 'DOSE_1_COV',\n",
    " 'DOSE_2_COV',\n",
    " 'FAB_COV',\n",
    " 'LOTE_1_COV',\n",
    " 'LOTE_2_COV',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma as colunas de data para o tipo datetime64[ns]\n",
    "df[datas] = df[datas].apply(pd.to_datetime,infer_datetime_format = True, errors='coerce')\n",
    "\n",
    "# Transforma as colunas de float_columns para o tipo float\n",
    "df[float_columns] = df[float_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Transforma as colunas de object_columns para o tipo object\n",
    "df[object_columns] = df[object_columns].astype(object)\n",
    "\n",
    "# Substitui os valores nulos por '--'\n",
    "df.replace('nan', np.nan, inplace=True)\n",
    "\n",
    "del object_columns, float_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação e manipulação de variáveis essenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a coluna IDADE_REGISTRO subtraindo a data do dia de registro no sistema pela data de nascimento, converte para ano e arredonda para nenhuma casa decimal\n",
    "df['IDADE_REGISTRO'] = ((df['DT_DIGITA'] - df['DT_NASC'])/ np.timedelta64(1, 'Y')).round()\n",
    "\n",
    "# Transforma a coluna 'NU_NOTIFIC' em string\n",
    "df['NU_NOTIFIC'] = df['NU_NOTIFIC'].apply(str)\n",
    "\n",
    "# Transforma a coluna de CPF em String e retira o .0 da direita\n",
    "df['NU_CPF'] = df['NU_CPF'].apply(str).apply(lambda x: x.replace('.0',''))\n",
    "\n",
    "# Cria uma coluna para reinternação e acrescenta 0 em todas as linhas, posteriormente, o que for identificado como reinternação terá 1\n",
    "df['REINTERNACAO'] = 0\n",
    "\n",
    "# Cria uma coluna com o código do outro registro a ser preenchido (dos registros que serão apagados)\n",
    "df['MANTER_E_ATUALIZAR_NU_NOTIFIC'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altera os valores que estãoe scritos como None para núlos\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "\n",
    "# Altera os valores que estãoe scritos como nan para núlos\n",
    "df.replace('nan', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valores Repetidos\n",
    "Cria pequenos Data Frames (df) com dados duplicados baseado em algumas condicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processo de identificação de casos duplicados\n"
     ]
    }
   ],
   "source": [
    "print('Iniciando processo de identificação de casos duplicados')\n",
    "\n",
    "# Cria um df com valores que se repetem em 'NM_PACIENT' e 'DT_NASC'\n",
    "df_nome = df[df[['NM_PACIENT','DT_NASC']].duplicated(keep=False)]\n",
    "\n",
    "# Cria o df df_cpf com os registros onde o cpf não são 'nan\n",
    "df_cpf = df[df['NU_CPF'].notnull()]\n",
    "# Deixa somente os registros duplicados\n",
    "df_cpf = df_cpf[df_cpf[['NU_CPF']].duplicated(keep=False)]\n",
    "\n",
    "# Junta os valores repetidos dos dois df acima\n",
    "df_repetidos = pd.concat([df_nome,df_cpf])\n",
    "\n",
    "# Apaga os registros que possuem valor repetido na coluna 'NU_NOTIFIC', deixando somente uma instância no 'df_repetidos'\n",
    "df_repetidos = df_repetidos.drop_duplicates(subset=['NU_NOTIFIC'], keep='last')\n",
    "\n",
    "# Apaga o 'df_nome', 'df_sem_nan_cpf' e o 'df_cpf'\n",
    "del df_cpf, df_nome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acrescentar descrição em REINTERNACAO\n",
    "### 0 = não possui repetição de nome nem CPF\n",
    "### 1 = Duplicidade que será mantida (Primeiro registro)\n",
    "### 2 = Duplicidade que será apagada (Segundo registro)\n",
    "### 3 = Reinternação ( Data de Primeiros Sintomas maior que 15 dias )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casos duplicados identificados\n"
     ]
    }
   ],
   "source": [
    "# Cria um loop que vai percorrer a coluna 'NM_PACIENT' de df_repetidos\n",
    "for nome in df_repetidos['NM_PACIENT']:\n",
    "\n",
    "    # Cria a variável linhas e adiciona os valor do número de linahs com nomes iguais\n",
    "    linhas = df_repetidos.loc[df_repetidos['NM_PACIENT'] == nome].shape[0]\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \n",
    "    ids = [''] * linhas\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\n",
    "    for qtd in range(linhas):\n",
    "        # Adiciona o index das linhas em ordem na lista ids\n",
    "        ids[qtd] = df_repetidos.loc[df_repetidos['NM_PACIENT'] == nome]['REINTERNACAO'].index[qtd]\n",
    "        \n",
    "            \n",
    "    # Cria uma variável data com o registro das datas de 'DT_SIN_PRI' dos nomes repetidos \n",
    "    data = df_repetidos.loc[df_repetidos['NM_PACIENT'] == nome]['DT_SIN_PRI']\n",
    "\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \n",
    "    dif = [''] * linhas\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\n",
    "    for qtd in range(linhas):\n",
    "        # Adiciona na lista a diferença de dias entre o primeiro registro e os demais\n",
    "        dif[qtd] = (data[ids[qtd]] - data[ids[0]]).days \n",
    "    # Apaga o primeiro registro da lista dif (é zero por padrão)\n",
    "    del dif[0]\n",
    "\n",
    "    # Variável para pegar o índice de ids\n",
    "    i = 1\n",
    "    # Irá criar um loop que percorrerá os valores das diferenças em dif\n",
    "    for diferenca in dif:\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre 0 e 15 \n",
    "        if diferenca <= 15 and diferenca >= 0:\n",
    "\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\n",
    "                # Caso seja 0, ele vai receber 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'MANTER_E_ATUALIZAR_NU_NOTIFIC'] =  df_repetidos['NU_NOTIFIC'][ids[0]]\n",
    "\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\n",
    "            \n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\n",
    "                # Caso seja 0, ele vai receber 1\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\n",
    "\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre -15 e 0\n",
    "        elif diferenca >= -15 and diferenca < 0:\n",
    "\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\n",
    "                # Caso seja 0, ele vai receber 1\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\n",
    "\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\n",
    "                # Caso seja 0, ele vai receber 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'MANTER_E_ATUALIZAR_NU_NOTIFIC'] = df_repetidos['NU_NOTIFIC'][ids[i]]\n",
    "\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\n",
    "\n",
    "        # Caso a diferença entre o primeiro e o segundo dia seja maior que 15 dias ou menor que -15, executa os códigos abaixo dentro do else\n",
    "        else:\n",
    "\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\n",
    "                # Caso seja 0, ele vai receber 3\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\n",
    "            \n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\n",
    "                # Caso seja 0, ele vai receber 3\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\n",
    "        i += 1\n",
    "\n",
    "              \n",
    "# Apaga os registros em df_repetidos onde o cpf for nulo\n",
    "df_repetidos = df_repetidos.loc[df_repetidos['NU_CPF'].notnull()]\n",
    "\n",
    "\n",
    "# Cria um loop que vai percorrer a coluna 'NM_PACIENT' de df_repetidos\n",
    "for cpf in df_repetidos['NU_CPF']:\n",
    "\n",
    "    # Cria a variável linhas e adiciona os valor do número de linahs com cpfs iguais\n",
    "    linhas = df_repetidos.loc[df_repetidos['NU_CPF'] == cpf].shape[0]\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \n",
    "    ids = [''] * linhas\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\n",
    "    for qtd in range(linhas):\n",
    "        # Adiciona o index das linhas em ordem na lista ids\n",
    "        ids[qtd] = df_repetidos.loc[df_repetidos['NU_CPF'] == cpf]['REINTERNACAO'].index[qtd]\n",
    "        \n",
    "            \n",
    "    # Cria uma variável data com o registro das datas de 'DT_SIN_PRI' dos cpfs repetidos \n",
    "    data = df_repetidos.loc[df_repetidos['NU_CPF'] == cpf]['DT_SIN_PRI']\n",
    "\n",
    "    # Cria uma lista vazia com a quantidade de espaços de linhas \n",
    "    dif = [''] * linhas\n",
    "    # Cria um loop a ser repetido pela quantidade de linhas\n",
    "    for qtd in range(linhas):\n",
    "        # Adiciona na lista a diferença de dias entre o primeiro registro e os demais\n",
    "        dif[qtd] = (data[ids[qtd]] - data[ids[0]]).days \n",
    "    # Apaga o primeiro registro da lista dif (é zero por padrão)\n",
    "    del dif[0]\n",
    "\n",
    "    # Variável para pegar o índice de ids\n",
    "    i = 1\n",
    "    # Irá criar um loop que percorrerá os valores das diferenças em dif\n",
    "    for diferenca in dif:\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre 0 e 15 \n",
    "        if diferenca <= 15 and diferenca >= 0:\n",
    "\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\n",
    "                # Caso seja 0, ele vai receber 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'MANTER_E_ATUALIZAR_NU_NOTIFIC'] = df_repetidos['NU_NOTIFIC'][ids[0]]\n",
    "\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 2\n",
    "            \n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\n",
    "                # Caso seja 0, ele vai receber 1\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 1\n",
    "\n",
    "        # Verifica se a diferença do dia do primeiro com o segundo registro está entre -15 e 0\n",
    "        elif diferenca >= -15 and diferenca < 0:\n",
    "\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\n",
    "                # Caso seja 0, ele vai receber 1\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 1\n",
    "\n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\n",
    "                # Caso seja 0, ele vai receber 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'MANTER_E_ATUALIZAR_NU_NOTIFIC'] = df_repetidos['NU_NOTIFIC'][ids[i]]\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 2\n",
    "\n",
    "        # Caso a diferença entre o primeiro e o segundo dia seja maior que 15 dias ou menor que -15, executa os códigos abaixo dentro do else\n",
    "        else:\n",
    "\n",
    "            # Verifica se o segundo registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'][ids[i]] == 0:\n",
    "                # Caso seja 0, ele vai receber 3\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[i]]), 'REINTERNACAO'] = 3\n",
    "            \n",
    "            # Verifica se o primeiro registro possui 0 em REINTERNACAO\n",
    "            if df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'][ids[0]] == 0:\n",
    "                # Caso seja 0, ele vai receber 3\n",
    "                df.loc[(df['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\n",
    "                df_repetidos.loc[(df_repetidos['NU_NOTIFIC'] == df_repetidos['NU_NOTIFIC'][ids[0]]), 'REINTERNACAO'] = 3\n",
    "        i += 1\n",
    "    \n",
    "# Apagas as variáveis usadas no código\n",
    "del df_repetidos, dif, diferenca, i, ids, linhas, nome,  qtd, cpf\n",
    "\n",
    "# transforma a coluna NU_NOTIFIC em index\n",
    "df.set_index('NU_NOTIFIC', inplace = True)\n",
    "\n",
    "print('Casos duplicados identificados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boletim = df.loc[df['REINTERNACAO'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlista_anos = []\\n\\nx = 0\\nwhile x < 10:\\n    # define a data do primeiro dia da primeira semana epidemológica do ano vigente\\n    start_date = str(Year(datetime.today().year+x).startdate())\\n\\n    # define a data do último dia da última semana epidemológica do ano vigente\\n    end_date = str(Year(datetime.today().year+x).enddate())\\n\\n    # Cria uma lista vazia\\n    lista_inicio_fim = []\\n\\n    # Coloca na primeira posição da lista o ano vigente\\n    lista_inicio_fim.append(datetime.today().year+x)\\n\\n    # Coloca na segunda posição da lista a primeira data do início das semanas epidemológicas\\n    lista_inicio_fim.append(start_date)\\n\\n    # Coloca na segunda posição da lista a primeira data do Fim das semanas epidemológicas\\n    lista_inicio_fim.append(end_date)\\n\\n    lista_anos.append(lista_inicio_fim)\\n\\n    x +=1\\n\\n\\n# Cria uma planilha com ano, Data de início e fim das semanas epidemiológicas de cada ano\\ndf_anos = pd.DataFrame(lista_anos, columns = ['ANO', 'INICIO', 'FIM'])\\n\\n# Transforma as colunas de data no tipo data\\ndf_anos[['INICIO', 'FIM']] = df_anos[['INICIO', 'FIM']].apply(pd.to_datetime,infer_datetime_format = True, errors='coerce')\\n\\n# Transforma a colunaANO em index\\ndf_anos.set_index('ANO', inplace = True)\\n\\n# Cria uma variável dia_inicial que recebe o primeiro dia da semana epidemologica do ano atual \\ndia_inicial = df_anos['INICIO'][datetime.now().year]\\n\\ndf_boletim = df.loc[df['DT_SIN_PRI']>= dia_inicial]\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lista_anos = []\n",
    "\n",
    "x = 0\n",
    "while x < 10:\n",
    "    # define a data do primeiro dia da primeira semana epidemológica do ano vigente\n",
    "    start_date = str(Year(datetime.today().year+x).startdate())\n",
    "\n",
    "    # define a data do último dia da última semana epidemológica do ano vigente\n",
    "    end_date = str(Year(datetime.today().year+x).enddate())\n",
    "\n",
    "    # Cria uma lista vazia\n",
    "    lista_inicio_fim = []\n",
    "\n",
    "    # Coloca na primeira posição da lista o ano vigente\n",
    "    lista_inicio_fim.append(datetime.today().year+x)\n",
    "\n",
    "    # Coloca na segunda posição da lista a primeira data do início das semanas epidemológicas\n",
    "    lista_inicio_fim.append(start_date)\n",
    "\n",
    "    # Coloca na segunda posição da lista a primeira data do Fim das semanas epidemológicas\n",
    "    lista_inicio_fim.append(end_date)\n",
    "\n",
    "    lista_anos.append(lista_inicio_fim)\n",
    "\n",
    "    x +=1\n",
    "\n",
    "\n",
    "# Cria uma planilha com ano, Data de início e fim das semanas epidemiológicas de cada ano\n",
    "df_anos = pd.DataFrame(lista_anos, columns = ['ANO', 'INICIO', 'FIM'])\n",
    "\n",
    "# Transforma as colunas de data no tipo data\n",
    "df_anos[['INICIO', 'FIM']] = df_anos[['INICIO', 'FIM']].apply(pd.to_datetime,infer_datetime_format = True, errors='coerce')\n",
    "\n",
    "# Transforma a colunaANO em index\n",
    "df_anos.set_index('ANO', inplace = True)\n",
    "\n",
    "# Cria uma variável dia_inicial que recebe o primeiro dia da semana epidemologica do ano atual \n",
    "dia_inicial = df_anos['INICIO'][datetime.now().year]\n",
    "\n",
    "df_boletim = df.loc[df['DT_SIN_PRI']>= dia_inicial]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando a planilha tratada e as planilha de duplicidades\n"
     ]
    }
   ],
   "source": [
    "print('Salvando a planilha tratada e as planilha de duplicidades')\n",
    "# Cria uma cópia do df antes de converter as datas para gerar as planilhas\n",
    "dff = df.copy(deep=True)\n",
    "\n",
    "# Converte as colunas do tipo data que estão no formato americano para o brasileiro\n",
    "for data in datas:\n",
    "    df[data] = df[data].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "del data\n",
    "\n",
    "for data in datas:\n",
    "    df_boletim[data] = df_boletim[data].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salva as planilhas na pasta df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoje = datetime.today().strftime('%d-%m-%Y')\n",
    "# Cria uma nova rota de pastas\n",
    "rota = '/duplicidades/duplicidades por hospitais/'\n",
    "\n",
    "rota = hoje + rota\n",
    "\n",
    "\n",
    "# Tenta criar a rota de pastas, caso já exista irá printar 'Pasta já Criada'\n",
    "try:\n",
    "    os.makedirs(rota)\n",
    "except OSError:\n",
    "    print('Pasta já criada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um df com os repetidos apagados \n",
    "df_repetidos_apagados = df.loc[df['REINTERNACAO']==2].sort_values(['NM_PACIENT'])\n",
    "# Salava uma planilha com os repetidos apagadoss\n",
    "rota_duplicidades_apagadas = hoje+'/duplicidades/duplicidades_apagadas.xlsx'\n",
    "# Salva a planilha\n",
    "df_repetidos_apagados.to_excel(rota_duplicidades_apagadas)\n",
    "\n",
    "# Cria uma planilha de apagados por hospitais\n",
    "df_repetidos_apagados_hospitais = df_repetidos_apagados\n",
    "\n",
    "\n",
    "# Salva uma planilha com os registros repetidos que não serão apagados\n",
    "rota_duplicidades_mantidas = hoje+'/duplicidades/duplicidades_mantidas.xlsx'\n",
    "df.loc[df['REINTERNACAO']==1].sort_values(['NM_PACIENT']).to_excel(rota_duplicidades_mantidas)\n",
    "\n",
    "# Todos valores repetidos desconsiderando as reinternações\n",
    "duplicidades_sem_reinternacoes = hoje+'/duplicidades/duplicidades_sem_reinternacoes.xlsx'\n",
    "pd.concat([df.loc[df['REINTERNACAO']==2],df.loc[df['REINTERNACAO']==1]]).drop_duplicates(keep='last').sort_values(['NM_PACIENT']).to_excel(duplicidades_sem_reinternacoes)\n",
    "\n",
    "# Salva uma planilha com todos os valores repetidos, incluindo as reinternações\n",
    "duplicidades_com_reinternacoes = hoje+'/duplicidades/duplicidades_com_reinternacoes.xlsx'\n",
    "df.loc[df['REINTERNACAO']!=0].sort_values(['NM_PACIENT']).to_excel(duplicidades_com_reinternacoes)\n",
    "\n",
    "# Salva uma planilha com todos os pacientes de reintenação\n",
    "reinternacoes = hoje+'/duplicidades/todas_reinternacoes.xlsx'\n",
    "df.loc[df['REINTERNACAO']==3].sort_values(['NM_PACIENT']).to_excel(reinternacoes)\n",
    "\n",
    "# Deixa no df somente os registros sem duplicidades, salvo os casos de reinternação\n",
    "df_boletim = df_boletim.loc[df['REINTERNACAO']!=2]\n",
    "\n",
    "# Salva uma planilha com \n",
    "boletim = hoje+'/Planilha para Boletim.xlsx'\n",
    "df_boletim.to_excel(boletim)\n",
    "\n",
    "del df_boletim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quais colunas irão ser enviadas para os Hospitais - A coluna de NU_NOTIFIC é o index da planilha e por isto não necessita estar definida aqui\n",
    "colunas_apagados = ['NU_CPF', 'NM_PACIENT', 'ID_UNIDADE', 'MANTER_E_ATUALIZAR_NU_NOTIFIC']\n",
    "\n",
    "# Deixa na planilha df_repetidos_apagados_hospitais somente as colunas definidas a cima\n",
    "df_repetidos_apagados_hospitais = df_repetidos_apagados_hospitais[colunas_apagados]\n",
    "\n",
    "del colunas_apagados, df_repetidos_apagados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar as planilhas de cada hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista chamada hospitais com todos os nomes dos hospitais que aparecem na planilha df_repetidos_apagados_hospitais\n",
    "hospitais = df_repetidos_apagados_hospitais.ID_UNIDADE.unique()\n",
    "\n",
    "# Cria uma variável extencao que serve para definir a extensão da planilha a ser salva\n",
    "extencao = '.xlsx'\n",
    "\n",
    "# Cria um loop que irá ocorrer a quantidade de hospitais na planilha df_repetidos_apagados_hospitais\n",
    "for x in range(hospitais.shape[0]):\n",
    "    # Cria uma variável nome_hospital com o nome do hospital que está sendo percorrido pela lista\n",
    "    nome_hospital = hospitais[x]\n",
    "\n",
    "    # Cria uma variável salvar que junta a rota, nome do hospital e a extensão Ex: bases/planilha dos hospitais apagar/HRAN.xlsx\n",
    "    salvar = rota+nome_hospital+extencao\n",
    "\n",
    "    # Na posição da lista que o loop está percorrendo, é feito um df somente com os registros de repetidos a serem apagados do hospital e\n",
    "    # salva uma planilha com o nome do hospital na rota criada em rota\n",
    "    df_repetidos_apagados_hospitais.loc[df_repetidos_apagados_hospitais['ID_UNIDADE']==hospitais[x]].to_excel(salvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planilha para Boletim salva\n",
      "Planilhas de duplicidades salva\n"
     ]
    }
   ],
   "source": [
    "df = dff\n",
    "\n",
    "df = df.loc[df['REINTERNACAO']!=2]\n",
    "\n",
    "\n",
    "# Apaga variáveis não mais utilizadas\n",
    "del df_repetidos_apagados_hospitais, dff, extencao, hospitais, nome_hospital, rota, salvar\n",
    "\n",
    "print('Planilha para Boletim salva')\n",
    "print('Planilhas de duplicidades salva')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualidade Inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processo de identificação de inconsisências\n"
     ]
    }
   ],
   "source": [
    "print('Iniciando processo de identificação de inconsisências')\n",
    "\n",
    "# Define quais serão as colunas de erros\n",
    "colunas_erros = ['HOMEM_PUERPERO', 'HOMEM_GRAVIDO', 'PREENCHER_UTI', 'PREENCHER_DATA_ENTRADA_UTI', 'PREENCHER_DATA_SAIDA_UTI', \n",
    "'OBITOS_SEM_HOSPITALIZACAO','CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5', 'PREENCHER_HOSPITALIZACAO', 'CASO_SEM_HOSPITALIZACAO', \n",
    "'PREENCHER_SUPORT_VEN', 'CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3', 'OBTO_COVID_POR_CRITERIO_CLINICO', 'ENCERRADOS_IMCOMPLETOS', \n",
    "'PREENCHER_DT_ENCERRA', 'PREENCHER_CLASSI_FIN', 'PREENCHER_EVOLUCAO', 'SRAG_NAO_ESPECIFICADO_CRITERIO_2_OU_4', 'SEM_SINTOMA',\n",
    "'SRAG_LABORATORIAL_SEM_RESULT', 'CLASSI_FIN_INFLUENZA_COM_COVID_+','MUNICIPIO_RES_BRASILIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HOMEM_PUERPERO'] = 0\n",
    "df['HOMEM_GRAVIDO'] = 0\n",
    "df['PREENCHER_UTI'] = 0\n",
    "df['PREENCHER_DATA_ENTRADA_UTI'] = 0\n",
    "df['PREENCHER_DATA_SAIDA_UTI'] = 0\n",
    "df['OBITOS_SEM_HOSPITALIZACAO'] = 0\n",
    "df['CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5'] = 0\n",
    "df['PREENCHER_HOSPITALIZACAO'] = 0\n",
    "df['CASO_SEM_HOSPITALIZACAO'] = 0\n",
    "df['PREENCHER_SUPORT_VEN'] = 0\n",
    "df['CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3'] = 0\n",
    "df['OBTO_COVID_POR_CRITERIO_CLINICO'] = 0\n",
    "df['ENCERRADOS_IMCOMPLETOS'] = 0\n",
    "df['PREENCHER_DT_ENCERRA'] = 0\n",
    "df['PREENCHER_CLASSI_FIN'] = 0\n",
    "df['PREENCHER_EVOLUCAO'] = 0\n",
    "df['SRAG_NAO_ESPECIFICADO_CRITERIO_2_OU_4'] = 0\n",
    "df['SEM_SINTOMA'] = 0\n",
    "df['SRAG_LABORATORIAL_SEM_RESULT'] = 0\n",
    "df['CLASSI_FIN_INFLUENZA_COM_COVID_+'] = 0\n",
    "df['MUNICIPIO_RES_BRASILIA'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria as colunas de erros em df e seta o valor 0 para todas as linhas das novas colunas\n",
    "df[colunas_erros] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine o index de df\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homens classificados como Puérpera\n",
    "'HOMEM_PUERPERO'\n",
    "\n",
    "# Cria uma lista com os index onde existe homem classificado como puérpera \n",
    "index_list = df.loc[df['CS_SEXO'] =='M'].loc[df['PUERPERA']==1,'HOMEM_PUERPERO'].index\n",
    "\n",
    "# Escreve 'Sim' na coluna HOMEM_PUERPERO onde existe homeme classificado como puérpero\n",
    "df.loc[df.index[index_list],'HOMEM_PUERPERO'] = 'Sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homens que não são classificados como CS_GESTANT (6), ignorado (9) ou 5 = Não\n",
    "'HOMEM_GRAVIDO'\n",
    "\n",
    "# Cria uma planilha somente com os registros de homens\n",
    "df_homem_gravido = df.loc[df['CS_SEXO']=='M']\n",
    "\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 1\n",
    "df_homem_gravido1 = df_homem_gravido.loc[df['CS_GESTANT']==1]\n",
    "\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 2\n",
    "df_homem_gravido2 = df_homem_gravido.loc[df['CS_GESTANT']==2]\n",
    "\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 3\n",
    "df_homem_gravido3 = df_homem_gravido.loc[df['CS_GESTANT']==3]\n",
    "\n",
    "#Cria uma planilha derivada da planilha de homens, onde o código CS_GESTANT é 4\n",
    "df_homem_gravido4 = df_homem_gravido.loc[df['CS_GESTANT']==4]\n",
    "\n",
    "# Junta as colunas criadas a cima com cada código\n",
    "df_homem_gravido = pd.concat([df_homem_gravido1, df_homem_gravido2, df_homem_gravido3, df_homem_gravido4])\n",
    "\n",
    "# Cria uma lista com os index nos registros de homens classificados como grávidos\n",
    "index_list = df_homem_gravido.index\n",
    "\n",
    "# Escreve 'Sim' na coluna HOMEM_GRAVIDO onde existe homeme classificado como grávidos\n",
    "df.loc[df.index[index_list],'HOMEM_GRAVIDO'] = 'Sim'\n",
    "\n",
    "del df_homem_gravido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTI = 9 ou nula\n",
    "'PREENCHER_UTI'\n",
    "\n",
    "# Cria a planilha df_inconsistentes_UTI onde UTI está nula ou 9\n",
    "df_inconsistentes_UTI = pd.concat([df[df['UTI'].isna()],df.loc[df['UTI']==9]])\n",
    "\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_inconsistentes_UTI\n",
    "df_inconsistentes_UTI['SUBTRACAO_MES_ATUAL'] = 0\n",
    "\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_inconsistentes_UTI e subtrair pelo mês atual, oresultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\n",
    "for x in df_inconsistentes_UTI.index:\n",
    "    df_inconsistentes_UTI['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_inconsistentes_UTI['DT_SIN_PRI'][x]).days/30\n",
    "\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\n",
    "df_inconsistentes_UTI = df_inconsistentes_UTI.loc[df_inconsistentes_UTI['SUBTRACAO_MES_ATUAL'] >= 6]\n",
    "\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e UTI está nula ou 9\n",
    "index_list = df_inconsistentes_UTI.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e UTI está nula ou 9\n",
    "df.loc[df.index[index_list],'PREENCHER_UTI'] = 'Preencher '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTI = 1 e sem data de entrada UTI\n",
    "'PREENCHER_DATA_ENTRADA_UTI'\n",
    "\n",
    "# Cria uma lista com os index onde existe homem classificado como puérpera \n",
    "index_list = df.loc[df['UTI'] ==1].loc[df['DT_ENTUTI'].isna(),'PREENCHER_DATA_ENTRADA_UTI'].index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_DATA_ENTRADA_UTI onde não existe data de entrada UTI\n",
    "df.loc[df.index[index_list],'PREENCHER_DATA_ENTRADA_UTI'] = 'Preencher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTI = 1 e sem data de saída UTI\n",
    "'PREENCHER_DATA_SAIDA_UTI'\n",
    "\n",
    "\n",
    "df_UTI_sem_data_saida = df.loc[df['UTI'] ==1].loc[df['DT_SAIDUTI'].isna()]\n",
    "\n",
    "\n",
    "\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_UTI_sem_data_saida \n",
    "df_UTI_sem_data_saida['SUBTRACAO_MES_ATUAL'] = 0\n",
    "\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_UTI_sem_data_saida e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\n",
    "for x in df_UTI_sem_data_saida.index:\n",
    "    df_UTI_sem_data_saida['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_UTI_sem_data_saida['DT_SIN_PRI'][x]).days/30\n",
    "\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\n",
    "df_UTI_sem_data_saida = df_UTI_sem_data_saida.loc[df_UTI_sem_data_saida['SUBTRACAO_MES_ATUAL'] >= 6]\n",
    "\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e UTI está nula ou 9\n",
    "index_list = df_UTI_sem_data_saida.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e UTI está nula ou 9\n",
    "df.loc[df.index[index_list],'PREENCHER_DATA_SAIDA_UTI'] = 'Preencher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Óbitos sem hospitalização\n",
    "'OBITOS_SEM_HOSPITALIZACAO'\n",
    "\n",
    "# Cria uma planilha somente com os registros de não hospitalizados\n",
    "df_nao_hospitalizacao_obito = df.loc[df['HOSPITAL']==2]\n",
    "\n",
    "#Cria uma planilha de não hospitalizados e vieram a óbito por covid\n",
    "df_nao_hospitalizacao_obito1 = df_nao_hospitalizacao_obito.loc[df['EVOLUCAO']==2]\n",
    "\n",
    "#Cria uma planilha de não hospitalizados e vieram a óbito por outras causas\n",
    "df_nao_hospitalizacao_obito2 = df_nao_hospitalizacao_obito.loc[df['EVOLUCAO']==3]\n",
    "\n",
    "# Junta as colunas criadas a cima\n",
    "df_nao_hospitalizacao_obito = pd.concat([df_nao_hospitalizacao_obito1, df_nao_hospitalizacao_obito2,])\n",
    "\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e UTI está nula ou 9\n",
    "index_list = df_nao_hospitalizacao_obito.index\n",
    "\n",
    "# Escreve 'Sim' na coluna OBITOS_SEM_HOSPITALIZACAO nos registros com mais de 6 meses e UTI está nula ou 9\n",
    "df.loc[df.index[index_list],'OBITOS_SEM_HOSPITALIZACAO'] = 'Verificar Hospitalização'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITERIO = 4 e TOMO_RES diferente de 1 ou 5\n",
    "'CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5'\n",
    "\n",
    "# Cria uma lista com os index onde critério = 4, TOMO_RES diferente de 1 e 5\n",
    "index_list = df.loc[df['CRITERIO'] ==4].loc[df['TOMO_RES']!=1].loc[df['TOMO_RES']!=5].index\n",
    "\n",
    "# Escreve 'Sim' na coluna CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5 onde CRITERIO = 4 e TOMO_RES diferente de 1 ou 5\n",
    "df.loc[df.index[index_list],'CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5'] = 'Verificar e Altera'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOSPITAL = ignorado ou vazio\n",
    "'PREENCHER_HOSPITALIZACAO'\n",
    "\n",
    "# CRIA UMA PLANILHA COM OS REGISTROS ONDE HOSPITAL = 9 OU NULO\n",
    "df_sem_hospitalizacao = pd.concat([df[df['HOSPITAL'].isna()],df.loc[df['HOSPITAL'] == 9]])\n",
    "\n",
    "# CRIA UMA lista COM OS index onde os REGISTROS HOSPITAL = 9 OU NULO\n",
    "index_list = df_sem_hospitalizacao.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_HOSPITALIZACAO onde HOSPITAL = ignorado ou vazio\n",
    "df.loc[df.index[index_list],'PREENCHER_HOSPITALIZACAO'] = 'Sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOSPITAL = 2 e EVOLUCAO = 1\n",
    "'CASO_SEM_HOSPITALIZACAO'\n",
    "\n",
    "# Cria uma lista com os index onde critério = 4, TOMO_RES diferente de 1 e 5\n",
    "index_list = df.loc[df['HOSPITAL'] == 2].loc[df['EVOLUCAO']==2].index\n",
    "\n",
    "# Escreve 'Sim' na coluna CURA_SEM_HOSPITALIZACAO onde HOSPITAL = 2 e EVOLUCAO = 1\n",
    "df.loc[df.index[index_list],'CASO_SEM_HOSPITALIZACAO'] = 'Verificar Hospitalização'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPORTE_VEN = 9 ou NAN\n",
    "'PREENCHER_SUPORT_VEN'\n",
    "\n",
    "# Cria uma planilha onde SUPORTE_VEN = 9 ou NAN\n",
    "df_sem_suporte_vent = pd.concat([df[df['SUPORT_VEN'].isna()],df.loc[df['SUPORT_VEN'] == 9]])\n",
    "\n",
    "# Cria uma lista com os index onde SUPORTE_VEN = 9 ou NAN\n",
    "index_list = df_sem_suporte_vent.index\n",
    "\n",
    "# Escreve 'Sim' na coluna CURA_SEM_HOSPITALIZACAO onde SUPORTE_VEN = 9 ou NAN\n",
    "df.loc[df.index[index_list],'PREENCHER_SUPORT_VEN'] = 'Sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSI_FIN = 3 E CLASSI_OUT = NAN\n",
    "'CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3'\n",
    "\n",
    "\n",
    "# Cria uma lista com os index onde CLASSI_FIN = 3 E CLASSI_OUT = NAN\n",
    "index_list = df.loc[df['CLASSI_FIN'] == 3].loc[df['CLASSI_OUT'].isna()].index\n",
    "\n",
    "# Escreve 'Sim' na coluna CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3 onde CLASSI_FIN = 3 E CLASSI_OUT = NAN\n",
    "df.loc[df.index[index_list],'CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3'] = 'Preencher Agente Etiológico'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSI_FIN = 5 EVOLUCAO = 2 E CRITERIO = 3\n",
    "'OBITO_COVID_POR_CRITERIO_CLINICO'\n",
    "\n",
    "# Cria uma lista com os index onde CLASSI_FIN = 5 EVOLUCAO = 2 E CRITERIO = 3\n",
    "index_list = df.loc[df['CLASSI_FIN'] == 5].loc[df['EVOLUCAO'] == 2].loc[df['CRITERIO'] == 3].index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3 onde CLASSI_FIN = 5 E EVOLUCAO = 2 E CRITERIO = 3\n",
    "df.loc[df.index[index_list],'OBITO_COVID_POR_CRITERIO_CLINICO'] = 'Encerrar por outro critério'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'ENCERRADOS_IMCOMPLETOS'\n",
    "\n",
    "# CRIA UMA PLANILHA df_encerrados_incompletos COM REGISTROS NÃO NULOS EM DT_ENCERRA\n",
    "df_encerrados_incompletos = df[df['DT_ENCERRA'].notnull()]\n",
    "\n",
    "# ADICIONA 0 NA COLUNA ENCERRADOS_IMCOMPLETOS\n",
    "df_encerrados_incompletos['ENCERRADOS_IMCOMPLETOS'] = 0 \n",
    "\n",
    "\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS Preencher CLASSI_FIN SE CLASSI_FIN ESTIVER NULO\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['CLASSI_FIN'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher CLASSI_FIN'\n",
    "\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS 'Preencher CRITERIO' SE CRITERIO ESTIVER NULO\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['CRITERIO'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher CRITERIO'\n",
    "\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS 'Preencher EVOLUCAO' SE EVOLUCAO ESTIVER NULO\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['EVOLUCAO'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher EVOLUCAO'\n",
    "\n",
    "# PREENCHE NA COLUNA  ENCERRADOS_IMCOMPLETOS 'Preencher DT_EVOLUCA' SE DT_EVOLUCA ESTIVER NULO\n",
    "df_encerrados_incompletos.loc[df_encerrados_incompletos['DT_EVOLUCA'].isnull(),'ENCERRADOS_IMCOMPLETOS'] = 'Preencher DT_EVOLUCA'   \n",
    "\n",
    "# Deixa somente os registros onde DT_ENCERRA não é nulo e tem ao menos um dos campos (75,76,77 ou 78) nulos\n",
    "df_encerrados_incompletos = df_encerrados_incompletos.loc[df_encerrados_incompletos['ENCERRADOS_IMCOMPLETOS']!=0]\n",
    "\n",
    "\n",
    "# Cria uma lista com os index de df_encerrados_incompletos\n",
    "index_list = df_encerrados_incompletos.index\n",
    "\n",
    "# Escreve o critério na coluna ENCERRADOS_IMCOMPLETOS nos REGISTROS NÃO NULOS EM DT_ENCERRA e sem critérios\n",
    "df.loc[df.index[index_list],'ENCERRADOS_IMCOMPLETOS'] = df_encerrados_incompletos['ENCERRADOS_IMCOMPLETOS']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 79 = nan\n",
    "'PREENCHER_DT_ENCERRA'\n",
    "\n",
    "# CRIA UMA PLANILHA df_sem_dt_encerramento COM VALORES ONDE DT_ENCERRA É NULA\n",
    "df_sem_dt_encerramento = df[df['DT_ENCERRA'].isna()]\n",
    "\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_sem_dt_encerramento \n",
    "df_sem_dt_encerramento['SUBTRACAO_MES_ATUAL'] = 0\n",
    "\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_sem_dt_encerramento e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\n",
    "for x in df_sem_dt_encerramento.index:\n",
    "    df_sem_dt_encerramento['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_sem_dt_encerramento['DT_SIN_PRI'][x]).days/30\n",
    "\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\n",
    "df_sem_dt_encerramento = df_sem_dt_encerramento.loc[df_sem_dt_encerramento['SUBTRACAO_MES_ATUAL'] >= 6]\n",
    "\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e 79 = nan\n",
    "index_list = df_sem_dt_encerramento.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e 79 = nan\n",
    "df.loc[df.index[index_list],'PREENCHER_DT_ENCERRA'] = 'Sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75= nan\n",
    "'PREENCHER_CLASSI_FIN'\n",
    "\n",
    "# CRIA UMA PLANILHA df_sem_classi_fim COM VALORES ONDE DT_ENCERRA É NULA\n",
    "df_sem_classi_fim = df[df['CLASSI_FIN'].isna()]\n",
    "\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_sem_classi_fim \n",
    "df_sem_classi_fim['SUBTRACAO_MES_ATUAL'] = 0\n",
    "\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_sem_classi_fim e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\n",
    "for x in df_sem_classi_fim.index:\n",
    "    df_sem_classi_fim['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_sem_classi_fim['DT_SIN_PRI'][x]).days/30\n",
    "\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\n",
    "df_sem_classi_fim = df_sem_classi_fim.loc[df_sem_classi_fim['SUBTRACAO_MES_ATUAL'] >= 6]\n",
    "\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses 75= nan\n",
    "index_list = df_sem_classi_fim.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e 75= nan\n",
    "df.loc[df.index[index_list],'PREENCHER_CLASSI_FIN'] = 'Sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77 = NAN\n",
    "'PREENCHER_EVOLUCAO'\n",
    "\n",
    "# CRIA UMA PLANILHA df_sem_evolucao COM VALORES ONDE DT_ENCERRA É NULA\n",
    "df_sem_evolucao = df[df['EVOLUCAO'].isna()]\n",
    "\n",
    "# Cria a coluna SUBTRACAO_MES_ATUAL na planilha df_sem_evolucao \n",
    "df_sem_evolucao['SUBTRACAO_MES_ATUAL'] = 0\n",
    "\n",
    "# Cria um loop que vai percorrer os valores de DT_SIN_PRI em df_sem_evolucao e subtrair pelo mês atual, o resultado da subtração aloca na variável SUBTRACAO_MES_ATUAL\n",
    "for x in df_sem_evolucao.index:\n",
    "    df_sem_evolucao['SUBTRACAO_MES_ATUAL'][x] = (datetime.now() - df_sem_evolucao['DT_SIN_PRI'][x]).days/30\n",
    "\n",
    "# Deixa na planilha df_inconsistentes_UTI somente valores que possuem 6 ou + meses de distância da data atual\n",
    "df_sem_evolucao = df_sem_evolucao.loc[df_sem_evolucao['SUBTRACAO_MES_ATUAL'] >= 6]\n",
    "\n",
    "# Cria uma lista com os index nos registros com mais de 6 meses e 77 = NAN\n",
    "index_list = df_sem_evolucao.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros com mais de 6 meses e 77 = NAN\n",
    "df.loc[df.index[index_list],'PREENCHER_EVOLUCAO'] = 'Sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75 = 4 E 76 = 2 OU 4\n",
    "'SRAG_NAO_ESPECIFICADO_CRITERIO_2_OU_4'\n",
    "\n",
    "# Cria uma planilha classi_fin4_criteirio_2_ou_4 com os casos onde classi_fin é 4\n",
    "classi_fin4_criteirio_2_ou_4 = df.loc[df['CLASSI_FIN']==4]\n",
    "\n",
    "# CRIA UMA PLANILHA classi_fin4_criteirio_2 ONDE CLASSI_FIN É 4 E CRITERIO = 2\n",
    "classi_fin4_criteirio_2 = classi_fin4_criteirio_2_ou_4.loc[classi_fin4_criteirio_2_ou_4['CRITERIO']==2]\n",
    "\n",
    "# CRIA UMA PLANILHA classi_fin4_criteirio_4 ONDE CLASSI_FIN É 4 E CRITERIO = 4\n",
    "classi_fin4_criteirio_4 = classi_fin4_criteirio_2_ou_4.loc[classi_fin4_criteirio_2_ou_4['CRITERIO']==4]\n",
    "\n",
    "# jUNTA AS PLANILHAS classi_fin4_criteirio_2 E classi_fin4_criteirio_4 NA PLANILHA classi_fin4_criteirio_2_ou_4\n",
    "classi_fin4_criteirio_2_ou_4 = pd.concat([classi_fin4_criteirio_2,classi_fin4_criteirio_4])\n",
    "\n",
    "# Cria uma lista com os index nos registros  75 = 4 E 76 = 2 OU 4\n",
    "index_list = classi_fin4_criteirio_2_ou_4.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros  75 = 4 E 76 = 2 OU 4\n",
    "df.loc[df.index[index_list],'SRAG_NAO_ESPECIFICADO_CRITERIO_2_OU_4'] = 'Encerrar por outro critério'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registros sem nenhum sintma\n",
    "'SEM_SINTOMA'\n",
    "\n",
    "# CRIA UMA LISTA COM as colunas dos sintomas\n",
    "colunas_sintomas = ['FEBRE','TOSSE','GARGANTA','DISPNEIA','DESC_RESP','SATURACAO','DIARREIA','VOMITO','DOR_ABD','FADIGA','PERD_OLFT','PERD_PALA','OUTRO_SIN','OUTRO_DES']\n",
    "\n",
    "# Cria uma planilha df_sem_sintomas com os valores de df\n",
    "df_sem_sintomas = df\n",
    "\n",
    "# Aloca na coluna SEM_SINTOMA a quantidade de sintomas nulos de cada linha\n",
    "df_sem_sintomas['SOMA'] = df_sem_sintomas[colunas_sintomas].isnull().sum(axis=1)\n",
    "\n",
    "# Deixa na planilha df_sem_sintomas somente os registro onde a coluna SEM_SINTOMA = 14 (quantidade de colunas de sintomas)\n",
    "df_sem_sintomas = df_sem_sintomas.loc[df_sem_sintomas['SOMA'] == 14]\n",
    "\n",
    "\n",
    "# Cria uma lista com os index dos registros sem sintomas\n",
    "index_list = df_sem_sintomas.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros sem nenhum sintma\n",
    "df.loc[df.index[index_list],'SEM_SINTOMA'] = 'Avaliar e Preencher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSI_FIN = 5 E CRITERIO = 1 E PCR_SARS2 e AN_SARS2 = NAN e RES_IGG e RES_IGM = NAN e !=1\n",
    "\n",
    "'SRAG_LABORATORIAL_SEM_RESULT'\n",
    "\n",
    "# Cria uma lista com os index onde existe 75 = 5 E 76 = 1 E PCR_SARS2 e AN_SARS2 = NAN e RES_IGG e RES_IGM = NAN e !=1\n",
    "index_list = df.loc[df['CLASSI_FIN'] ==5].loc[df['CRITERIO']==1].loc[df['PCR_SARS2'].isna()].loc[df['AN_SARS2'].isna()].loc[df['RES_IGG'].isna()].loc[df['RES_IGM'].isna()].index\n",
    "\n",
    "# Escreve 'Preencher colunas PCR_SARS2, AN_SARS2, RES_IGG ou RES_IGM' na coluna HOMEM_PUERPERO onde existe homeme classificado como puérpero\n",
    "df.loc[df.index[index_list],'SRAG_LABORATORIAL_SEM_RESULT'] = 'Preencher Resultado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campo 75 CLASSI_FIN influenza = 1 --> PCR_SARS2 ou AN_SARS2 = 1 ou RES_IGG ou RES_IGM = 1\n",
    "\n",
    "'CLASSI_FIN_INFLUENZA_COM_COVID_+'\n",
    "\n",
    "# Cria uma planilha df_inflenza_e_covid com os registros onde CLASSI_FIN = 1\n",
    "df_inflenza_e_covid = df.loc[df['CLASSI_FIN']==1]\n",
    "\n",
    "# Cria uma planilha df_inflenza_e_covid_PCR_SARS2 com os registros de df_inflenza_e_covid onde PCR_SARS2 = 1\n",
    "df_inflenza_e_covid_PCR_SARS2 = df_inflenza_e_covid.loc[df_inflenza_e_covid['PCR_SARS2']==1]\n",
    "\n",
    "# Cria uma planilha df_inflenza_e_covid_AN_SARS2 com os registros de df_inflenza_e_covid onde AN_SARS2 = 1\n",
    "df_inflenza_e_covid_AN_SARS2 = df_inflenza_e_covid.loc[df_inflenza_e_covid['AN_SARS2']==1]\n",
    "\n",
    "# Cria uma planilha df_inflenza_e_covid_RES_IGG com os registros de df_inflenza_e_covid onde RES_IGG = 1\n",
    "df_inflenza_e_covid_RES_IGG = df_inflenza_e_covid.loc[df_inflenza_e_covid['RES_IGG']==1]\n",
    "\n",
    "# Cria uma planilha df_inflenza_e_covid_RES_IGM com os registros de df_inflenza_e_covid onde RES_IGM = 1\n",
    "df_inflenza_e_covid_RES_IGM = df_inflenza_e_covid.loc[df_inflenza_e_covid['RES_IGM']==1]\n",
    "\n",
    "# Junta as 4 planilhas criadas a cima e aloca na planilha df_inflenza_e_covid\n",
    "df_inflenza_e_covid = pd.concat([df_inflenza_e_covid_PCR_SARS2, df_inflenza_e_covid_AN_SARS2, df_inflenza_e_covid_RES_IGG, df_inflenza_e_covid_RES_IGM])\n",
    "\n",
    "# Cria uma lista com os index dos registros 75 CLASSI_FIN influenza = 1 --> PCR_SARS2 ou AN_SARS2 = 1 ou RES_IGG ou RES_IGM = 1\n",
    "index_list = df_inflenza_e_covid.index\n",
    "\n",
    "# Escreve 'Sim' na coluna PREENCHER_UTI nos registros 75 CLASSI_FIN influenza = 1 --> PCR_SARS2 ou AN_SARS2 = 1 ou RES_IGG ou RES_IGM = 1\n",
    "df.loc[df.index[index_list],'CLASSI_FIN_INFLUENZA_COM_COVID_+'] = 'Alterar CLASSI_FIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreve Sim nos registros com valor = BRASILIA na coluna  ID_MN_RESI\n",
    "df.loc[df['ID_MN_RESI']=='BRASILIA', 'MUNICIPIO_RES_BRASILIA'] = 'Alterar para RA de Moradia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_finais = ['ID_UNIDADE','NM_PACIENT','NU_CPF','DT_NASC','HOMEM_PUERPERO', 'HOMEM_GRAVIDO', 'PREENCHER_UTI', 'PREENCHER_DATA_ENTRADA_UTI', 'PREENCHER_DATA_SAIDA_UTI', \n",
    "'OBITOS_SEM_HOSPITALIZACAO','CRIETERIO_4_TOMO_RES_DIFERENTE_1_OU_5', 'PREENCHER_HOSPITALIZACAO', 'CASO_SEM_HOSPITALIZACAO', \n",
    "'PREENCHER_SUPORT_VEN', 'CLASSI_OUT_VAZIA_SE_CLASSI_FIN_3', 'OBTO_COVID_POR_CRITERIO_CLINICO', 'ENCERRADOS_IMCOMPLETOS', \n",
    "'PREENCHER_DT_ENCERRA', 'PREENCHER_CLASSI_FIN', 'PREENCHER_EVOLUCAO', 'SRAG_NAO_ESPECIFICADO_CRITERIO_2_OU_4', 'SEM_SINTOMA',\n",
    "'SRAG_LABORATORIAL_SEM_RESULT', 'CLASSI_FIN_INFLUENZA_COM_COVID_+','MUNICIPIO_RES_BRASILIA','OBSERVA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma a coluna NU_NOTIFIC em index\n",
    "df.set_index('NU_NOTIFIC', inplace = True)\n",
    "\n",
    "# Substitui os valores zeros por nulos\n",
    "df.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Aloca na coluna ERROS a quantidade de ERROS de cada linha\n",
    "df['ERROS'] = df[colunas_erros].isnull().sum(axis=1)\n",
    "\n",
    "# Deixa na planilha df somente os registros que possuem ao menos 1 erro\n",
    "df = df.loc[df['ERROS'] != 21]\n",
    "\n",
    "# Deixa somente as colunas de erros e de ID_UNIDADE\n",
    "df = df[colunas_finais]\n",
    "\n",
    "# Substitui os valores nulos por '--'\n",
    "df.replace(np.nan, '--', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "del classi_fin4_criteirio_2, classi_fin4_criteirio_2_ou_4, classi_fin4_criteirio_4, colunas_erros,colunas_finais, colunas_sintomas, df_UTI_sem_data_saida, df_encerrados_incompletos, df_homem_gravido1,df_homem_gravido2, df_homem_gravido3, df_homem_gravido4, df_inconsistentes_UTI, df_inflenza_e_covid_AN_SARS2, df_inflenza_e_covid_PCR_SARS2, df_inflenza_e_covid_RES_IGG, df_inflenza_e_covid, df_inflenza_e_covid_RES_IGM, df_nao_hospitalizacao_obito, df_nao_hospitalizacao_obito1, df_nao_hospitalizacao_obito2, df_sem_classi_fim, df_sem_dt_encerramento, df_sem_evolucao, df_sem_hospitalizacao, df_sem_sintomas, df_sem_suporte_vent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DT_NASC'] = df['DT_NASC'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova rota de pastas\n",
    "rota = '/inconsistencias/inconsistencias por hospitais/'\n",
    "\n",
    "rota = hoje + rota\n",
    "\n",
    "# Tenta criar a rota de pastas, caso já exista irá printar 'Pasta já Criada'\n",
    "try:\n",
    "    os.makedirs(rota)\n",
    "except OSError:\n",
    "    print('Pasta já criada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva a planilha com o nome dos hospitais e os erros\n",
    "rota_todas_inconsistencias = hoje+'/inconsistencias/todas_inconsistencias.xlsx'\n",
    "df.to_excel(rota_todas_inconsistencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planilhas salvas\n"
     ]
    }
   ],
   "source": [
    "# Cria uma lista chamada hospitais com todos os nomes dos hospitais que aparecem na planilha df\n",
    "hospitais = df.ID_UNIDADE.unique()\n",
    "\n",
    "# Cria uma variável extencao que serve para definir a extensão da planilha a ser salva\n",
    "extencao = '.xlsx'\n",
    "\n",
    "# Cria um loop que irá ocorrer a quantidade de hospitais na planilha df\n",
    "for x in range(hospitais.shape[0]):\n",
    "    # Cria uma variável nome_hospital com o nome do hospital que está sendo percorrido pela lista\n",
    "    nome_hospital = hospitais[x]\n",
    "\n",
    "    # Cria uma variável salvar que junta a rota, nome do hospital e a extensão Ex: bases/planilha dos hospitais apagar/HRAN.xlsx\n",
    "    salvar = rota+nome_hospital+extencao\n",
    "\n",
    "    # Na posição da lista que o loop está percorrendo, é feito um df somente com os registros de repetidos a serem apagados do hospital e\n",
    "    # salva uma planilha com o nome do hospital na rota criada em rota\n",
    "    df_hospital = df.loc[df['ID_UNIDADE']==hospitais[x]]\n",
    "\n",
    "    # troca os 2 tracinhos por um valor nulo\n",
    "    df_hospital.replace('--', np.nan, inplace=True)\n",
    "\n",
    "    # Apaga as colunas onde todos os valores são nulos\n",
    "    df_hospital.dropna(axis=1, how='all', inplace = True)\n",
    "\n",
    "    df_hospital.replace(np.nan, '--', inplace=True)\n",
    "\n",
    "\n",
    "    # Salva a planilha em excel \n",
    "    df_hospital.to_excel(salvar)\n",
    "\n",
    "# del df, df_hospital\n",
    "\n",
    "print('Planilhas salvas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim do processo de qualidade\n"
     ]
    }
   ],
   "source": [
    "print('Fim do processo de qualidade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs =  df.loc[df['OBSERVA'].notnull()]\n",
    "df_obs['TRANSFERIDO'] = 0\n",
    "\n",
    "for x in range(df_obs.shape[0]):\n",
    "    if 'TRANS ' in df_obs['OBSERVA'][x]:\n",
    "        df_obs.loc[df_obs['OBSERVA'] == df_obs['OBSERVA'][x], 'TRANSFERIDO'] = 1\n",
    "\n",
    "df_obs = df_obs.loc[df_obs['TRANSFERIDO']==1]\n",
    "\n",
    "del df_obs['TRANSFERIDO']\n",
    "\n",
    "df_obs.replace('--', np.nan, inplace=True)\n",
    "\n",
    "# Apaga as colunas onde todos os valores são nulos\n",
    "df_obs.dropna(axis=1, how='all', inplace = True)\n",
    "\n",
    "\n",
    "rota_inconsistencias_obs = hoje+'/inconsistencias/Inconcistencias com obs Trans.xlsx'\n",
    "\n",
    "df_obs.to_excel(rota_inconsistencias_obs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57ed44ba291eb9ea2f94c9ed0fadf5c2f3c02c5ec5fe57a4fa6fa1aed17845c7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
